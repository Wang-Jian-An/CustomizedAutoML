{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes, load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from AutoML_Flow.MLEnv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作範例 - Breast Cancer（Binary Classification）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = load_breast_cancer(as_frame = True)[\"data\"]\n",
    "rawData = pd.concat([rawData, load_breast_cancer(as_frame = True)[\"target\"]], axis = 1)\n",
    "rawData = rawData.rename(\n",
    "    columns = {\n",
    "        i: i.replace(\" \", \"_\") for i in rawData.columns\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy Training\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.4152910646714806\n",
      "最佳 Threshold 0.5916166947959994\n",
      "最佳 Threshold 0.24135262029258028\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.5118385565812936\n",
      "最佳 Threshold 0.5684330983951182\n",
      "最佳 Threshold 0.5932968879034061\n",
      "最佳 Threshold 0.6156693342176238\n",
      "最佳 Threshold 0.09837085689299221\n",
      "最佳 Threshold 0.5651568140419021\n",
      "最佳 Threshold 0.5773090889039049\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.32971747141136115\n",
      "最佳 Threshold 0.5823900431936774\n",
      "最佳 Threshold 0.5819245971474829\n",
      "最佳 Threshold 0.29418626478735616\n",
      "最佳 Threshold 0.4423830021439144\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.5587269703121135\n",
      "最佳 Threshold 0.44182794853705476\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.2413509031467571\n",
      "最佳 Threshold 0.5211391880005246\n",
      "最佳 Threshold 0.7497002310949266\n",
      "最佳 Threshold 0.6591245658625552\n",
      "最佳 Threshold 0.5443686372145962\n",
      "最佳 Threshold 0.6813806424311202\n",
      "最佳 Threshold 0.5587269703121135\n",
      "最佳 Threshold 0.4423798903202152\n",
      "最佳 Threshold 0.9899941583562332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwang-jian-an\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125212-ln8e53vh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/ln8e53vh' target=\"_blank\">Flow_0_train</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/ln8e53vh' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/ln8e53vh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ln8e53vh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28468d2a0dbb40e7b8528f3bfeb360c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.6651278409090909, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99707</td></tr><tr><td>cross_entropy</td><td>0.02031</td></tr><tr><td>f1_0</td><td>0.99582</td></tr><tr><td>f1_1</td><td>0.99774</td></tr><tr><td>f1_macro</td><td>0.99678</td></tr><tr><td>f1_micro</td><td>0.99707</td></tr><tr><td>macro_precision</td><td>0.99583</td></tr><tr><td>macro_recall</td><td>0.99775</td></tr><tr><td>micro_precision</td><td>0.99707</td></tr><tr><td>micro_recall</td><td>0.99707</td></tr><tr><td>prc_auc_0</td><td>0.1993</td></tr><tr><td>prc_auc_1</td><td>1.0</td></tr><tr><td>precision_0</td><td>0.99167</td></tr><tr><td>precision_1</td><td>1.0</td></tr><tr><td>recall_0</td><td>1.0</td></tr><tr><td>recall_1</td><td>0.9955</td></tr><tr><td>roc_auc</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_0_train</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/ln8e53vh' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/ln8e53vh</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125212-ln8e53vh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ln8e53vh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387abeb3eaae4aee9f5927b4b674b214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113024900098228, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125215-cz094fgx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/cz094fgx' target=\"_blank\">Flow_0_vali</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/cz094fgx' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/cz094fgx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cz094fgx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3345df35ed324cb3bea04a349792662d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.5591416917893244, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>1.0</td></tr><tr><td>cross_entropy</td><td>0.01509</td></tr><tr><td>f1_0</td><td>1.0</td></tr><tr><td>f1_1</td><td>1.0</td></tr><tr><td>f1_macro</td><td>1.0</td></tr><tr><td>f1_micro</td><td>1.0</td></tr><tr><td>macro_precision</td><td>1.0</td></tr><tr><td>macro_recall</td><td>1.0</td></tr><tr><td>micro_precision</td><td>1.0</td></tr><tr><td>micro_recall</td><td>1.0</td></tr><tr><td>prc_auc_0</td><td>0.21813</td></tr><tr><td>prc_auc_1</td><td>1.0</td></tr><tr><td>precision_0</td><td>1.0</td></tr><tr><td>precision_1</td><td>1.0</td></tr><tr><td>recall_0</td><td>1.0</td></tr><tr><td>recall_1</td><td>1.0</td></tr><tr><td>roc_auc</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_0_vali</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/cz094fgx' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/cz094fgx</a><br/>Synced 4 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125215-cz094fgx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cz094fgx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a36c79353443c0bc0931ff696237eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112745811179695, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125224-hmsk6cub</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/hmsk6cub' target=\"_blank\">Flow_0_test</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/hmsk6cub' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/hmsk6cub</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy Training\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.4966565364387161\n",
      "最佳 Threshold 0.5462109640565063\n",
      "最佳 Threshold 0.8470242278388741\n",
      "最佳 Threshold 0.5420980850711229\n",
      "最佳 Threshold 0.5949624326440507\n",
      "最佳 Threshold 0.7586592236939729\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.6064940202365127\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.3843326928558285\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.615677437262213\n",
      "最佳 Threshold 0.50468803892891\n",
      "最佳 Threshold 0.9353907714026712\n",
      "最佳 Threshold 0.5684538939861355\n",
      "最佳 Threshold 0.6055058708085943\n",
      "最佳 Threshold 0.9353907714026712\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.5562479951180859\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.5690413479868675\n",
      "最佳 Threshold 0.527875047850378\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.384330998802136\n",
      "最佳 Threshold 0.5486176858221348\n",
      "最佳 Threshold 0.9562512826204239\n",
      "最佳 Threshold 0.5684330983951182\n",
      "最佳 Threshold 0.5267426850379248\n",
      "最佳 Threshold 0.9899941583562332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hmsk6cub) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb76f733e2740099c40110ac1652c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96491</td></tr><tr><td>cross_entropy</td><td>0.1068</td></tr><tr><td>f1_0</td><td>0.95918</td></tr><tr><td>f1_1</td><td>0.96923</td></tr><tr><td>f1_macro</td><td>0.96421</td></tr><tr><td>f1_micro</td><td>0.96491</td></tr><tr><td>macro_precision</td><td>0.96686</td></tr><tr><td>macro_recall</td><td>0.96219</td></tr><tr><td>micro_precision</td><td>0.96491</td></tr><tr><td>micro_recall</td><td>0.96491</td></tr><tr><td>prc_auc_0</td><td>0.26118</td></tr><tr><td>prc_auc_1</td><td>0.99427</td></tr><tr><td>precision_0</td><td>0.97917</td></tr><tr><td>precision_1</td><td>0.95455</td></tr><tr><td>recall_0</td><td>0.94</td></tr><tr><td>recall_1</td><td>0.98438</td></tr><tr><td>roc_auc</td><td>0.99281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_0_test</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/hmsk6cub' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/hmsk6cub</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125224-hmsk6cub/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hmsk6cub). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0259b873c178482eacd5840d7a4d44da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112544155265722, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125257-j95pr7my</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/j95pr7my' target=\"_blank\">Flow_1_train</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/j95pr7my' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/j95pr7my</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:j95pr7my) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceab8b239ff3479f906392b0e4a247b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.006 MB uploaded\\r'), FloatProgress(value=0.6783134554006384, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9912</td></tr><tr><td>cross_entropy</td><td>0.02443</td></tr><tr><td>f1_0</td><td>0.98745</td></tr><tr><td>f1_1</td><td>0.99323</td></tr><tr><td>f1_macro</td><td>0.99034</td></tr><tr><td>f1_micro</td><td>0.9912</td></tr><tr><td>macro_precision</td><td>0.9894</td></tr><tr><td>macro_recall</td><td>0.99129</td></tr><tr><td>micro_precision</td><td>0.9912</td></tr><tr><td>micro_recall</td><td>0.9912</td></tr><tr><td>prc_auc_0</td><td>0.1993</td></tr><tr><td>prc_auc_1</td><td>0.99994</td></tr><tr><td>precision_0</td><td>0.98333</td></tr><tr><td>precision_1</td><td>0.99548</td></tr><tr><td>recall_0</td><td>0.9916</td></tr><tr><td>recall_1</td><td>0.99099</td></tr><tr><td>roc_auc</td><td>0.99989</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_1_train</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/j95pr7my' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/j95pr7my</a><br/>Synced 4 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125257-j95pr7my/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:j95pr7my). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7afd51b9cd4e68bcedf09ab98895be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112424165993515, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125306-q641zndt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/q641zndt' target=\"_blank\">Flow_1_vali</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/q641zndt' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/q641zndt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:q641zndt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe0efa145b14efe8ca77490adf883ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.5588287488908606, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>1.0</td></tr><tr><td>cross_entropy</td><td>0.01545</td></tr><tr><td>f1_0</td><td>1.0</td></tr><tr><td>f1_1</td><td>1.0</td></tr><tr><td>f1_macro</td><td>1.0</td></tr><tr><td>f1_micro</td><td>1.0</td></tr><tr><td>macro_precision</td><td>1.0</td></tr><tr><td>macro_recall</td><td>1.0</td></tr><tr><td>micro_precision</td><td>1.0</td></tr><tr><td>micro_recall</td><td>1.0</td></tr><tr><td>prc_auc_0</td><td>0.21813</td></tr><tr><td>prc_auc_1</td><td>1.0</td></tr><tr><td>precision_0</td><td>1.0</td></tr><tr><td>precision_1</td><td>1.0</td></tr><tr><td>recall_0</td><td>1.0</td></tr><tr><td>recall_1</td><td>1.0</td></tr><tr><td>roc_auc</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_1_vali</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/q641zndt' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/q641zndt</a><br/>Synced 4 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125306-q641zndt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:q641zndt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76e75b41fe44f6a822092bc4acc0b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112147100114574, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125321-nznrzxy6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/nznrzxy6' target=\"_blank\">Flow_1_test</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/nznrzxy6' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/nznrzxy6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy Training\n",
      "最佳 Threshold 0.6778241032479019\n",
      "最佳 Threshold 0.18716218274546612\n",
      "最佳 Threshold 0.30217437498983135\n",
      "最佳 Threshold 0.1529843842837671\n",
      "最佳 Threshold 0.1529843842837671\n",
      "最佳 Threshold 0.5704122954464149\n",
      "最佳 Threshold 0.7040441568843022\n",
      "最佳 Threshold 0.1529843842837671\n",
      "最佳 Threshold 0.2413514835009372\n",
      "最佳 Threshold 0.384330998802136\n",
      "最佳 Threshold 0.24135164843905046\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.24135211293751252\n",
      "最佳 Threshold 0.38433064729375715\n",
      "最佳 Threshold 0.24135305913571983\n",
      "最佳 Threshold 0.3843321762200065\n",
      "最佳 Threshold 0.2413506953801306\n",
      "最佳 Threshold 0.3843308271421434\n",
      "最佳 Threshold 0.29572210042919816\n",
      "最佳 Threshold 0.24135270569966347\n",
      "最佳 Threshold 0.5542764714880567\n",
      "最佳 Threshold 0.37435893906423\n",
      "最佳 Threshold 0.24135229170965683\n",
      "最佳 Threshold 0.3843315004833716\n",
      "最佳 Threshold 0.2413522045130697\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.5844612704976203\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.3843326909355475\n",
      "最佳 Threshold 0.4615258534299649\n",
      "最佳 Threshold 0.9899941583562332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nznrzxy6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68823ed3aeb4c03ba7af34a0fdc17bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94737</td></tr><tr><td>cross_entropy</td><td>0.10918</td></tr><tr><td>f1_0</td><td>0.93878</td></tr><tr><td>f1_1</td><td>0.95385</td></tr><tr><td>f1_macro</td><td>0.94631</td></tr><tr><td>f1_micro</td><td>0.94737</td></tr><tr><td>macro_precision</td><td>0.94886</td></tr><tr><td>macro_recall</td><td>0.94437</td></tr><tr><td>micro_precision</td><td>0.94737</td></tr><tr><td>micro_recall</td><td>0.94737</td></tr><tr><td>prc_auc_0</td><td>0.26119</td></tr><tr><td>prc_auc_1</td><td>0.99427</td></tr><tr><td>precision_0</td><td>0.95833</td></tr><tr><td>precision_1</td><td>0.93939</td></tr><tr><td>recall_0</td><td>0.92</td></tr><tr><td>recall_1</td><td>0.96875</td></tr><tr><td>roc_auc</td><td>0.99281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_1_test</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/nznrzxy6' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/nznrzxy6</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125321-nznrzxy6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nznrzxy6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e981105414a4fc4844839bb080883e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112213799626463, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125353-0z68l4uv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/0z68l4uv' target=\"_blank\">Flow_2_train</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/0z68l4uv' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/0z68l4uv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:0z68l4uv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5e55ec012e4901be80c36f03eb1db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.7943991492378589, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>1.0</td></tr><tr><td>cross_entropy</td><td>0.02047</td></tr><tr><td>f1_0</td><td>1.0</td></tr><tr><td>f1_1</td><td>1.0</td></tr><tr><td>f1_macro</td><td>1.0</td></tr><tr><td>f1_micro</td><td>1.0</td></tr><tr><td>macro_precision</td><td>1.0</td></tr><tr><td>macro_recall</td><td>1.0</td></tr><tr><td>micro_precision</td><td>1.0</td></tr><tr><td>micro_recall</td><td>1.0</td></tr><tr><td>prc_auc_0</td><td>0.1993</td></tr><tr><td>prc_auc_1</td><td>1.0</td></tr><tr><td>precision_0</td><td>1.0</td></tr><tr><td>precision_1</td><td>1.0</td></tr><tr><td>recall_0</td><td>1.0</td></tr><tr><td>recall_1</td><td>1.0</td></tr><tr><td>roc_auc</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_2_train</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/0z68l4uv' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/0z68l4uv</a><br/>Synced 4 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125353-0z68l4uv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:0z68l4uv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c7792555c84d81b045118775a12b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112695311506588, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125401-9ar6ce7r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/9ar6ce7r' target=\"_blank\">Flow_2_vali</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/9ar6ce7r' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/9ar6ce7r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9ar6ce7r) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e45184da2b34a7fa44b59275f376009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.558436944937833, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>1.0</td></tr><tr><td>cross_entropy</td><td>0.01624</td></tr><tr><td>f1_0</td><td>1.0</td></tr><tr><td>f1_1</td><td>1.0</td></tr><tr><td>f1_macro</td><td>1.0</td></tr><tr><td>f1_micro</td><td>1.0</td></tr><tr><td>macro_precision</td><td>1.0</td></tr><tr><td>macro_recall</td><td>1.0</td></tr><tr><td>micro_precision</td><td>1.0</td></tr><tr><td>micro_recall</td><td>1.0</td></tr><tr><td>prc_auc_0</td><td>0.21813</td></tr><tr><td>prc_auc_1</td><td>1.0</td></tr><tr><td>precision_0</td><td>1.0</td></tr><tr><td>precision_1</td><td>1.0</td></tr><tr><td>recall_0</td><td>1.0</td></tr><tr><td>recall_1</td><td>1.0</td></tr><tr><td>roc_auc</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_2_vali</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/9ar6ce7r' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/9ar6ce7r</a><br/>Synced 4 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125401-9ar6ce7r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:9ar6ce7r). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae568a81a80459fb0d01627db832d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112430011336175, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125409-x9mc09a1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/x9mc09a1' target=\"_blank\">Flow_2_test</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/x9mc09a1' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/x9mc09a1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy Training\n",
      "最佳 Threshold 0.901639296769282\n",
      "最佳 Threshold 0.6156791506186637\n",
      "最佳 Threshold 0.5169211609003085\n",
      "最佳 Threshold 0.7586576842750771\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.5216764718141297\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.5678730668518822\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.7586592236939729\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.5173213912735908\n",
      "最佳 Threshold 0.8470257685684576\n",
      "最佳 Threshold 0.5678730668518822\n",
      "最佳 Threshold 0.5169211609003085\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.5972515452587767\n",
      "最佳 Threshold 0.8470242278388741\n",
      "最佳 Threshold 0.7040441568843022\n",
      "最佳 Threshold 0.6853536261679749\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.384330998802136\n",
      "最佳 Threshold 0.5344593448446763\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.5169211609003085\n",
      "最佳 Threshold 0.3843323638862662\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.5964837917182625\n",
      "最佳 Threshold 0.9899941583562332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/wangjianan/python-venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:x9mc09a1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a448248b14c9470490aae3121db287dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96491</td></tr><tr><td>cross_entropy</td><td>0.09891</td></tr><tr><td>f1_0</td><td>0.95833</td></tr><tr><td>f1_1</td><td>0.9697</td></tr><tr><td>f1_macro</td><td>0.96402</td></tr><tr><td>f1_micro</td><td>0.96491</td></tr><tr><td>macro_precision</td><td>0.97059</td></tr><tr><td>macro_recall</td><td>0.96</td></tr><tr><td>micro_precision</td><td>0.96491</td></tr><tr><td>micro_recall</td><td>0.96491</td></tr><tr><td>prc_auc_0</td><td>0.26117</td></tr><tr><td>prc_auc_1</td><td>0.99512</td></tr><tr><td>precision_0</td><td>1.0</td></tr><tr><td>precision_1</td><td>0.94118</td></tr><tr><td>recall_0</td><td>0.92</td></tr><tr><td>recall_1</td><td>1.0</td></tr><tr><td>roc_auc</td><td>0.99375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_2_test</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/x9mc09a1' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/x9mc09a1</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125409-x9mc09a1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:x9mc09a1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc427b9243146fda0ffdd91292502dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112333733278017, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125445-qini76y0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/qini76y0' target=\"_blank\">Flow_3_train</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/qini76y0' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/qini76y0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:qini76y0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981a1e96c264495eb83b7c8e62d1fa1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.006 MB uploaded\\r'), FloatProgress(value=0.6773550423658415, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98827</td></tr><tr><td>cross_entropy</td><td>0.04715</td></tr><tr><td>f1_0</td><td>0.98305</td></tr><tr><td>f1_1</td><td>0.99103</td></tr><tr><td>f1_macro</td><td>0.98704</td></tr><tr><td>f1_micro</td><td>0.98827</td></tr><tr><td>macro_precision</td><td>0.98903</td></tr><tr><td>macro_recall</td><td>0.98514</td></tr><tr><td>micro_precision</td><td>0.98827</td></tr><tr><td>micro_recall</td><td>0.98827</td></tr><tr><td>prc_auc_0</td><td>0.19932</td></tr><tr><td>prc_auc_1</td><td>0.99686</td></tr><tr><td>precision_0</td><td>0.99145</td></tr><tr><td>precision_1</td><td>0.98661</td></tr><tr><td>recall_0</td><td>0.97479</td></tr><tr><td>recall_1</td><td>0.9955</td></tr><tr><td>roc_auc</td><td>0.99568</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_3_train</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/qini76y0' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/qini76y0</a><br/>Synced 4 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125445-qini76y0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:qini76y0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacc7f099c73492ea72350cdc2bac0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112693767063319, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125454-pynpyqw6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/pynpyqw6' target=\"_blank\">Flow_3_vali</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/pynpyqw6' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/pynpyqw6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pynpyqw6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966210e59e04eb1aaa5dcf2d7e0c0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.5589852758559517, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>cross_entropy</td><td>▁</td></tr><tr><td>f1_0</td><td>▁</td></tr><tr><td>f1_1</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>macro_precision</td><td>▁</td></tr><tr><td>macro_recall</td><td>▁</td></tr><tr><td>micro_precision</td><td>▁</td></tr><tr><td>micro_recall</td><td>▁</td></tr><tr><td>prc_auc_0</td><td>▁</td></tr><tr><td>prc_auc_1</td><td>▁</td></tr><tr><td>precision_0</td><td>▁</td></tr><tr><td>precision_1</td><td>▁</td></tr><tr><td>recall_0</td><td>▁</td></tr><tr><td>recall_1</td><td>▁</td></tr><tr><td>roc_auc</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>1.0</td></tr><tr><td>cross_entropy</td><td>0.01505</td></tr><tr><td>f1_0</td><td>1.0</td></tr><tr><td>f1_1</td><td>1.0</td></tr><tr><td>f1_macro</td><td>1.0</td></tr><tr><td>f1_micro</td><td>1.0</td></tr><tr><td>macro_precision</td><td>1.0</td></tr><tr><td>macro_recall</td><td>1.0</td></tr><tr><td>micro_precision</td><td>1.0</td></tr><tr><td>micro_recall</td><td>1.0</td></tr><tr><td>prc_auc_0</td><td>0.21813</td></tr><tr><td>prc_auc_1</td><td>1.0</td></tr><tr><td>precision_0</td><td>1.0</td></tr><tr><td>precision_1</td><td>1.0</td></tr><tr><td>recall_0</td><td>1.0</td></tr><tr><td>recall_1</td><td>1.0</td></tr><tr><td>roc_auc</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Flow_3_vali</strong> at: <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/pynpyqw6' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/pynpyqw6</a><br/>Synced 4 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240128_125454-pynpyqw6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pynpyqw6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7003c0aaea274945b45ff11fef692ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112539744418528, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wangjianan/CustomizedAutoML/wandb/run-20240128_125505-jttvj3iv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/jttvj3iv' target=\"_blank\">Flow_3_test</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/jttvj3iv' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240128/runs/jttvj3iv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy Training\n",
      "最佳 Threshold 0.614990833119174\n",
      "最佳 Threshold 0.6156773810472529\n",
      "最佳 Threshold 0.38433131405156856\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.5623378460220594\n",
      "最佳 Threshold 0.5306541315031943\n",
      "最佳 Threshold 0.384330998802136\n",
      "最佳 Threshold 0.32971747141136115\n",
      "最佳 Threshold 0.42282548250299573\n",
      "最佳 Threshold 0.6156770499302485\n",
      "最佳 Threshold 0.615679124188561\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.67029114071128\n",
      "最佳 Threshold 0.609502090974151\n",
      "最佳 Threshold 0.3634704875843834\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.6156773810472529\n",
      "最佳 Threshold 0.5753400850306146\n",
      "最佳 Threshold 0.1529843842837671\n",
      "最佳 Threshold 0.4574064107131827\n",
      "最佳 Threshold 0.6156776133205051\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.384330627796835\n",
      "最佳 Threshold 0.4233981715789217\n",
      "最佳 Threshold 0.24135092784756415\n",
      "最佳 Threshold 0.5901744341044745\n",
      "最佳 Threshold 0.46461906733517805\n"
     ]
    }
   ],
   "source": [
    "from AutoML_Flow.Model_Training_and_Evaluation_Flow import modelTrainingFlow\n",
    "allResult = list()\n",
    "trainData, testData = train_test_split(rawData, test_size = 0.2, shuffle = True) \n",
    "trainData, valiData = train_test_split(trainData, test_size = 0.25, shuffle = True) \n",
    "for oneFE in featureEngineerFlow:\n",
    "    totalResult = modelTrainingFlow(\n",
    "        trainData = trainData,\n",
    "        valiData = valiData,\n",
    "        testData = testData,\n",
    "        inputFeatures = trainData.drop(columns = [\"target\"]).columns.tolist(), \n",
    "        target = \"target\", \n",
    "        targetType = \"classification\",\n",
    "        ml_methods = oneFE,\n",
    "        hyperparameter_tuning_method = \"default\", \n",
    "        hyperparameter_tuning_epochs = 1, \n",
    "        HTMetric = \"cross_entropy\", \n",
    "        thresholdMetric = \"f1_1\", \n",
    "        featureSelection = oneFE[\"FeatureSelection\"],\n",
    "        modelNameList = [\n",
    "            # [\"Random Forest with Entropy\"],\n",
    "            [\"LightGBM\", \"XGBoost\", \"Random Forest with Entropy\"] * 10, \n",
    "        ], \n",
    "        fitBestModel = False,\n",
    "        metaLearner = \"XGBoost\", \n",
    "        modelFilePath = \"./\", \n",
    "        importanceMethod = [\"None\"],\n",
    "        wandb_config = {\n",
    "            \"project_name\": \"test_wandb_20240128\",\n",
    "            \"entity\": \"wang-jian-an\",\n",
    "        }\n",
    "    )\n",
    "    result = totalResult.fit()\n",
    "    allResult.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Evaluation': [[{'ID': 'Flow_0_2024-01-28 10:28:14',\n",
       "    'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "    'Set': 'train',\n",
       "    'Meta-Learner': 'XGBoost',\n",
       "    'Features': ['mean_radius',\n",
       "     'mean_texture',\n",
       "     'mean_perimeter',\n",
       "     'mean_area',\n",
       "     'mean_smoothness',\n",
       "     'mean_compactness',\n",
       "     'mean_concavity',\n",
       "     'mean_concave_points',\n",
       "     'mean_symmetry',\n",
       "     'mean_fractal_dimension',\n",
       "     'radius_error',\n",
       "     'texture_error',\n",
       "     'perimeter_error',\n",
       "     'area_error',\n",
       "     'smoothness_error',\n",
       "     'compactness_error',\n",
       "     'concavity_error',\n",
       "     'concave_points_error',\n",
       "     'symmetry_error',\n",
       "     'fractal_dimension_error',\n",
       "     'worst_radius',\n",
       "     'worst_texture',\n",
       "     'worst_perimeter',\n",
       "     'worst_area',\n",
       "     'worst_smoothness',\n",
       "     'worst_compactness',\n",
       "     'worst_concavity',\n",
       "     'worst_concave_points',\n",
       "     'worst_symmetry',\n",
       "     'worst_fractal_dimension'],\n",
       "    'FeatureSelection': 'None',\n",
       "    'Imbalanced': 'None',\n",
       "    'Decomposition': 'None',\n",
       "    'Standardization': 'None',\n",
       "    'Number_of_Data': {1: 214, 0: 127}},\n",
       "   {'ID': 'Flow_1_2024-01-28 10:28:14',\n",
       "    'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "    'Set': 'vali',\n",
       "    'Meta-Learner': 'XGBoost',\n",
       "    'Features': ['mean_radius',\n",
       "     'mean_texture',\n",
       "     'mean_perimeter',\n",
       "     'mean_area',\n",
       "     'mean_smoothness',\n",
       "     'mean_compactness',\n",
       "     'mean_concavity',\n",
       "     'mean_concave_points',\n",
       "     'mean_symmetry',\n",
       "     'mean_fractal_dimension',\n",
       "     'radius_error',\n",
       "     'texture_error',\n",
       "     'perimeter_error',\n",
       "     'area_error',\n",
       "     'smoothness_error',\n",
       "     'compactness_error',\n",
       "     'concavity_error',\n",
       "     'concave_points_error',\n",
       "     'symmetry_error',\n",
       "     'fractal_dimension_error',\n",
       "     'worst_radius',\n",
       "     'worst_texture',\n",
       "     'worst_perimeter',\n",
       "     'worst_area',\n",
       "     'worst_smoothness',\n",
       "     'worst_compactness',\n",
       "     'worst_concavity',\n",
       "     'worst_concave_points',\n",
       "     'worst_symmetry',\n",
       "     'worst_fractal_dimension'],\n",
       "    'FeatureSelection': 'None',\n",
       "    'Imbalanced': 'None',\n",
       "    'Decomposition': 'None',\n",
       "    'Standardization': 'None',\n",
       "    'Number_of_Data': {1: 66, 0: 48}},\n",
       "   {'ID': 'Flow_2_2024-01-28 10:28:14',\n",
       "    'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "    'Set': 'test',\n",
       "    'Meta-Learner': 'XGBoost',\n",
       "    'Features': ['mean_radius',\n",
       "     'mean_texture',\n",
       "     'mean_perimeter',\n",
       "     'mean_area',\n",
       "     'mean_smoothness',\n",
       "     'mean_compactness',\n",
       "     'mean_concavity',\n",
       "     'mean_concave_points',\n",
       "     'mean_symmetry',\n",
       "     'mean_fractal_dimension',\n",
       "     'radius_error',\n",
       "     'texture_error',\n",
       "     'perimeter_error',\n",
       "     'area_error',\n",
       "     'smoothness_error',\n",
       "     'compactness_error',\n",
       "     'concavity_error',\n",
       "     'concave_points_error',\n",
       "     'symmetry_error',\n",
       "     'fractal_dimension_error',\n",
       "     'worst_radius',\n",
       "     'worst_texture',\n",
       "     'worst_perimeter',\n",
       "     'worst_area',\n",
       "     'worst_smoothness',\n",
       "     'worst_compactness',\n",
       "     'worst_concavity',\n",
       "     'worst_concave_points',\n",
       "     'worst_symmetry',\n",
       "     'worst_fractal_dimension'],\n",
       "    'FeatureSelection': 'None',\n",
       "    'Imbalanced': 'None',\n",
       "    'Decomposition': 'None',\n",
       "    'Standardization': 'None',\n",
       "    'Number_of_Data': {1: 77, 0: 37}}],\n",
       "  [{'f1_1': 0.9929742388758782,\n",
       "    'f1_0': 0.988235294117647,\n",
       "    'f1_macro': 0.9906047664967625,\n",
       "    'f1_micro': 0.9912023460410557,\n",
       "    'prc_auc_1': 0.9974597265263587,\n",
       "    'prc_auc_0': 0.2149408567663601,\n",
       "    'precision_1': 0.9953051643192489,\n",
       "    'precision_0': 0.984375,\n",
       "    'macro_precision': 0.9898400821596245,\n",
       "    'micro_precision': 0.9912023460410557,\n",
       "    'recall_1': 0.9906542056074766,\n",
       "    'recall_0': 0.9921259842519685,\n",
       "    'macro_recall': 0.9913900949297225,\n",
       "    'micro_recall': 0.9912023460410557,\n",
       "    'accuracy': 0.9912023460410557,\n",
       "    'roc_auc': 0.9966517035837811,\n",
       "    'cross_entropy': 0.04227214334982614,\n",
       "    'fpr': [0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007874015748031496,\n",
       "     0.007874015748031496,\n",
       "     0.015748031496062992,\n",
       "     0.015748031496062992,\n",
       "     1.0],\n",
       "    'tpr': [0.0,\n",
       "     0.004672897196261682,\n",
       "     0.5841121495327103,\n",
       "     0.5841121495327103,\n",
       "     0.9906542056074766,\n",
       "     0.9906542056074766,\n",
       "     1.0,\n",
       "     1.0],\n",
       "    'True_value': [1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1],\n",
       "    'Predict_value': [1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1],\n",
       "    'Predict_prob_value': [0.9968861671123045,\n",
       "     0.0002852882603894385,\n",
       "     0.9993000829730507,\n",
       "     0.9988394460728354,\n",
       "     0.9992747812246835,\n",
       "     7.119303162366629e-05,\n",
       "     0.999878184242002,\n",
       "     0.9427485948138159,\n",
       "     0.9971679182395438,\n",
       "     0.9778591004915945,\n",
       "     0.991317676486653,\n",
       "     0.0001413613168519558,\n",
       "     0.9982506423013494,\n",
       "     0.9961912631979766,\n",
       "     0.9991049003504396,\n",
       "     0.0006090275533463223,\n",
       "     0.9994126883827594,\n",
       "     0.9732992970826811,\n",
       "     0.011731957077705224,\n",
       "     0.020092853260706048,\n",
       "     0.9995729903216538,\n",
       "     0.9919557653946669,\n",
       "     0.0004067785396212942,\n",
       "     0.00012883607782630105,\n",
       "     0.00020369133880538025,\n",
       "     0.999932926214098,\n",
       "     0.9824288312840523,\n",
       "     0.0021328603050478965,\n",
       "     0.9948466232873387,\n",
       "     0.9590590248612038,\n",
       "     0.00015901028370322824,\n",
       "     0.05664193477312047,\n",
       "     0.9826250571849242,\n",
       "     0.0001256444225008322,\n",
       "     0.9936293392116461,\n",
       "     0.9995672849675252,\n",
       "     0.0005472033146168221,\n",
       "     0.003259529005558383,\n",
       "     0.0012434222188702796,\n",
       "     0.9999394357019146,\n",
       "     0.9989053203405406,\n",
       "     0.0013830730254281987,\n",
       "     0.9996958190869851,\n",
       "     0.9999328389487042,\n",
       "     0.00023849803373823643,\n",
       "     0.9452932391728408,\n",
       "     0.9992943519953129,\n",
       "     0.9999262671680319,\n",
       "     0.9996191093883999,\n",
       "     0.012506614711032113,\n",
       "     0.9830373768505919,\n",
       "     0.9821704169585186,\n",
       "     0.00014272301115197353,\n",
       "     0.9998903033296329,\n",
       "     0.06969213368856883,\n",
       "     0.9981674284703727,\n",
       "     0.9999273945359034,\n",
       "     0.8899404750060662,\n",
       "     0.9993765337460884,\n",
       "     0.991972912622616,\n",
       "     0.00020641388652482002,\n",
       "     0.9972055942069893,\n",
       "     0.011386355827219,\n",
       "     0.25064602001345615,\n",
       "     0.999560627446117,\n",
       "     0.06641698408812224,\n",
       "     0.034980144604517115,\n",
       "     0.9801397323630804,\n",
       "     0.8980750287818718,\n",
       "     0.00045243334942965727,\n",
       "     0.9107673650287189,\n",
       "     0.9998440716811429,\n",
       "     0.9992070657137023,\n",
       "     0.9998612962188292,\n",
       "     0.8762480606225372,\n",
       "     0.999391758415715,\n",
       "     0.9994449226882359,\n",
       "     0.9965555234616903,\n",
       "     0.9997881574473211,\n",
       "     0.9988524114301336,\n",
       "     0.015607482913234856,\n",
       "     0.9695595934869105,\n",
       "     0.014494223488000757,\n",
       "     0.9918068476777678,\n",
       "     0.9978510929346561,\n",
       "     0.9993815452497983,\n",
       "     0.9977244059868905,\n",
       "     0.00011920612130858057,\n",
       "     0.20730875016069952,\n",
       "     0.00014104403524957924,\n",
       "     0.8591303115959111,\n",
       "     0.9824086752810965,\n",
       "     0.9331325906564293,\n",
       "     0.0001292052146017926,\n",
       "     0.0008164837832281684,\n",
       "     0.9459249509069678,\n",
       "     0.00015499419038691239,\n",
       "     0.9976980845842732,\n",
       "     0.9998025071736727,\n",
       "     0.9999437394108522,\n",
       "     0.9204182134027677,\n",
       "     0.9981198645290574,\n",
       "     0.9998023177531957,\n",
       "     0.9884585879206889,\n",
       "     0.9984519345386685,\n",
       "     0.9984365474718568,\n",
       "     0.002567961064430471,\n",
       "     0.9989720292191204,\n",
       "     0.9975581702164511,\n",
       "     0.9976200921429758,\n",
       "     0.00014467279756404767,\n",
       "     0.0005552701557978194,\n",
       "     0.9998454016077325,\n",
       "     0.9999258981418803,\n",
       "     0.0002674983201794024,\n",
       "     0.06374530039829514,\n",
       "     0.0014888235528180474,\n",
       "     0.001078816701212082,\n",
       "     0.0017268413786885532,\n",
       "     0.0005592915717528,\n",
       "     0.9997825996602033,\n",
       "     0.9986988487277604,\n",
       "     0.002261913172480611,\n",
       "     0.9973958273310444,\n",
       "     0.9851479822166074,\n",
       "     0.9988918184505675,\n",
       "     0.0010365116583866381,\n",
       "     0.9997557407952695,\n",
       "     0.9999196207485265,\n",
       "     0.9992495810754175,\n",
       "     0.00013638156349791527,\n",
       "     0.01379727281603427,\n",
       "     0.9987958277100583,\n",
       "     7.948205419098014e-05,\n",
       "     0.9999407560822232,\n",
       "     0.9988720143658054,\n",
       "     0.12664810442759025,\n",
       "     0.9995659010014212,\n",
       "     0.9985784515511487,\n",
       "     0.9803812978038984,\n",
       "     0.9971396806347709,\n",
       "     0.9936522041335778,\n",
       "     0.9917950125735048,\n",
       "     0.9814345175203647,\n",
       "     0.051645094442674296,\n",
       "     9.065470113387854e-05,\n",
       "     0.9995794429069942,\n",
       "     0.9979356359436777,\n",
       "     0.9989217182301279,\n",
       "     0.02363838227943062,\n",
       "     0.998902406110366,\n",
       "     0.0013196164018891554,\n",
       "     0.9999263909582844,\n",
       "     0.9998516877091711,\n",
       "     0.06994754464103152,\n",
       "     0.9998777219502402,\n",
       "     0.9992264863976026,\n",
       "     0.999530376882542,\n",
       "     0.0008049970358253238,\n",
       "     0.9949111853422543,\n",
       "     0.9976450675719364,\n",
       "     0.997986873198664,\n",
       "     0.9946677591938595,\n",
       "     0.9999376768316921,\n",
       "     0.997292960348313,\n",
       "     0.9957810037009499,\n",
       "     0.9988054191248161,\n",
       "     0.9998900937403049,\n",
       "     0.05335514122175875,\n",
       "     0.9994940976390981,\n",
       "     0.9983364744397586,\n",
       "     0.9999452808632161,\n",
       "     0.9757297343861373,\n",
       "     0.9992351481481504,\n",
       "     0.9997219738679419,\n",
       "     0.05057157847115068,\n",
       "     0.9984163522066495,\n",
       "     0.9992342391023531,\n",
       "     0.03918016148623447,\n",
       "     0.011019777259541086,\n",
       "     0.9606177998267424,\n",
       "     0.00013953936521040336,\n",
       "     0.004202848404859096,\n",
       "     0.0009976599473553625,\n",
       "     0.005368242210617167,\n",
       "     0.18738065508887117,\n",
       "     0.9825676037384815,\n",
       "     0.9998610231088253,\n",
       "     0.00019704139755871768,\n",
       "     0.15099817404364407,\n",
       "     0.9646366468970485,\n",
       "     0.9990122854293622,\n",
       "     0.999234190140609,\n",
       "     0.9989543491288351,\n",
       "     0.9939132845668215,\n",
       "     0.9990431511265555,\n",
       "     0.00015004019013870588,\n",
       "     0.06243969429534359,\n",
       "     0.0028562175441065162,\n",
       "     0.9971306741395235,\n",
       "     0.0014257900840960538,\n",
       "     0.9989988769865011,\n",
       "     0.0040368384801176115,\n",
       "     0.015191486410097496,\n",
       "     0.9637675164397409,\n",
       "     0.008738433201767122,\n",
       "     0.0002616910268087779,\n",
       "     0.9868571873035897,\n",
       "     0.005257282371052675,\n",
       "     0.9989422511126789,\n",
       "     0.00019585195373746306,\n",
       "     0.0016389330311448722,\n",
       "     0.0008381088284777354,\n",
       "     0.027346337374150494,\n",
       "     0.9077344065622923,\n",
       "     0.05526524145462583,\n",
       "     0.9861824646575837,\n",
       "     0.9939656184061061,\n",
       "     0.00835069142829019,\n",
       "     0.0977739479408272,\n",
       "     0.9987557989928108,\n",
       "     0.9996576422888607,\n",
       "     0.6899722606181118,\n",
       "     0.922102220485771,\n",
       "     0.9959452883161133,\n",
       "     0.9998719085103024,\n",
       "     0.9809853723473452,\n",
       "     0.9219410101484075,\n",
       "     0.9995373001537329,\n",
       "     0.9978903329480614,\n",
       "     0.9939659582711009,\n",
       "     0.9978430964637414,\n",
       "     0.9998388836049769,\n",
       "     0.0017492746591218488,\n",
       "     0.04659502916768193,\n",
       "     0.0013000664698679984,\n",
       "     0.9948245129224931,\n",
       "     0.995817758164913,\n",
       "     0.9991985289856785,\n",
       "     0.9025870670069917,\n",
       "     0.9988216117907818,\n",
       "     0.010265873142643435,\n",
       "     0.009873639598193085,\n",
       "     0.00022687821659426,\n",
       "     0.9995152247860943,\n",
       "     7.433682061625712e-05,\n",
       "     0.01615218039200345,\n",
       "     0.9988266792745866,\n",
       "     0.0005605166142522041,\n",
       "     0.036803413637197996,\n",
       "     0.9988330284765542,\n",
       "     0.999888215253944,\n",
       "     0.9080074789632425,\n",
       "     0.997401549163907,\n",
       "     0.9921749785740668,\n",
       "     0.00514967691737584,\n",
       "     0.9988061192536314,\n",
       "     0.9970834137274428,\n",
       "     0.8951362219789956,\n",
       "     0.0015354938322021277,\n",
       "     0.9979255073937165,\n",
       "     0.0001579828032890699,\n",
       "     0.0004362487951896324,\n",
       "     0.00013852656469477535,\n",
       "     0.9998438375073158,\n",
       "     0.9997820749991843,\n",
       "     0.9998133179182381,\n",
       "     0.99813895764554,\n",
       "     0.9999251330429596,\n",
       "     0.018449543506022525,\n",
       "     0.9931467761147384,\n",
       "     0.0008336245699523228,\n",
       "     0.9965514289266804,\n",
       "     0.00014933848558691304,\n",
       "     0.10021645296471426,\n",
       "     0.9979523916536513,\n",
       "     0.9824785598248199,\n",
       "     0.9999654443417758,\n",
       "     0.004992179306291604,\n",
       "     0.994620451000254,\n",
       "     0.9998284680796722,\n",
       "     0.9997919724207666,\n",
       "     0.9965678779458254,\n",
       "     0.9987380986740065,\n",
       "     0.9994664528132435,\n",
       "     0.9999189318061699,\n",
       "     0.9989103160888184,\n",
       "     0.9989564647286874,\n",
       "     0.9699789373547579,\n",
       "     0.9940252219669489,\n",
       "     0.00012776439556150282,\n",
       "     0.6060082252941151,\n",
       "     0.026343143213404786,\n",
       "     0.9996233959216301,\n",
       "     0.9985943535202247,\n",
       "     0.00019109304071093105,\n",
       "     0.9958329950454898,\n",
       "     0.0008023413546998464,\n",
       "     0.9999258299003849,\n",
       "     0.0001823876824135182,\n",
       "     0.9995686420910457,\n",
       "     0.9384815858595112,\n",
       "     0.99964445408124,\n",
       "     0.9994844833852651,\n",
       "     0.0005767149010565891,\n",
       "     0.000794783618414349,\n",
       "     0.02387012145190611,\n",
       "     0.00022617446517485273,\n",
       "     0.9996245946356045,\n",
       "     0.9964007943043256,\n",
       "     0.6433464331098729,\n",
       "     0.00018443551374049718,\n",
       "     0.9890586301042017,\n",
       "     0.00014949122313477904,\n",
       "     0.02187668311831934,\n",
       "     0.00015661138627354984,\n",
       "     0.04827043979109549,\n",
       "     0.0007974305090574262,\n",
       "     0.09036424433998266,\n",
       "     0.9992519655250482,\n",
       "     0.9986827716149431,\n",
       "     0.9252905256903456,\n",
       "     0.9994463777329021,\n",
       "     0.9991705444511668,\n",
       "     0.9975448389571636,\n",
       "     0.9991207907918367,\n",
       "     0.9869172992844041,\n",
       "     0.004889764015958067,\n",
       "     0.00023220718589436726,\n",
       "     8.326114043664658e-05,\n",
       "     0.9995887411996968,\n",
       "     0.00014297592319850212,\n",
       "     0.0006364047253370112,\n",
       "     0.868988158303527,\n",
       "     0.9978419853918817,\n",
       "     0.9750901005503178,\n",
       "     0.9995091429854941,\n",
       "     0.9998454414609109,\n",
       "     0.10773154482283283,\n",
       "     0.010936611978120115,\n",
       "     0.998254992643739],\n",
       "    'Best_Threshold': [0.7586576842750771,\n",
       "     0.7586576842750771,\n",
       "     0.6156785788838928,\n",
       "     0.6156776133205051,\n",
       "     0.4914574557115674,\n",
       "     0.5996598443541759,\n",
       "     0.7586576842750771,\n",
       "     0.7119975119492042,\n",
       "     0.6227988940244247,\n",
       "     0.5682289332585385,\n",
       "     0.7586576842750771,\n",
       "     0.6156792825597568,\n",
       "     0.7586571292329795,\n",
       "     0.6156776133205051,\n",
       "     0.6156769483111665,\n",
       "     0.835881891281252,\n",
       "     0.7586576842750771,\n",
       "     0.6156779886683341,\n",
       "     0.7040441568843022,\n",
       "     0.6781711065558306,\n",
       "     0.6156777129332512,\n",
       "     0.7586576842750771,\n",
       "     0.7586587950625204,\n",
       "     0.6156769483111665,\n",
       "     0.6156776133205051,\n",
       "     0.6156776133205051,\n",
       "     0.5996598443541759,\n",
       "     0.6156776133205051,\n",
       "     0.7586576842750771,\n",
       "     0.6156769483111665]},\n",
       "   {'f1_1': 1.0,\n",
       "    'f1_0': 1.0,\n",
       "    'f1_macro': 1.0,\n",
       "    'f1_micro': 1.0,\n",
       "    'prc_auc_1': 1.0,\n",
       "    'prc_auc_0': 0.24848491638149664,\n",
       "    'precision_1': 1.0,\n",
       "    'precision_0': 1.0,\n",
       "    'macro_precision': 1.0,\n",
       "    'micro_precision': 1.0,\n",
       "    'recall_1': 1.0,\n",
       "    'recall_0': 1.0,\n",
       "    'macro_recall': 1.0,\n",
       "    'micro_recall': 1.0,\n",
       "    'accuracy': 1.0,\n",
       "    'roc_auc': 1.0,\n",
       "    'cross_entropy': 0.010278323118145803,\n",
       "    'fpr': [0.0, 0.0, 0.0, 1.0],\n",
       "    'tpr': [0.0, 0.015151515151515152, 1.0, 1.0],\n",
       "    'True_value': [0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1],\n",
       "    'Predict_value': [0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1],\n",
       "    'Predict_prob_value': [0.00012191321868270515,\n",
       "     0.9975703685183603,\n",
       "     0.9832002064373843,\n",
       "     0.9995488402091319,\n",
       "     0.9999670002336264,\n",
       "     0.0005141226266622415,\n",
       "     0.998855617198923,\n",
       "     0.00011728314679759147,\n",
       "     0.9899706472832269,\n",
       "     0.9999416215563026,\n",
       "     0.9540071286269907,\n",
       "     0.9974251952625502,\n",
       "     0.0001900590904549761,\n",
       "     0.9939283426804951,\n",
       "     0.999781250965827,\n",
       "     0.002260857949296141,\n",
       "     0.95951551080786,\n",
       "     0.003225205753321785,\n",
       "     0.9956443377236641,\n",
       "     0.0008249090058881012,\n",
       "     0.0024027107222221638,\n",
       "     0.9993514045057084,\n",
       "     0.990955044617065,\n",
       "     0.05550783186185883,\n",
       "     0.9996014683061182,\n",
       "     0.020195343656626785,\n",
       "     0.9990907146714386,\n",
       "     0.00012143508139888516,\n",
       "     0.9604137084804448,\n",
       "     0.060981438470802646,\n",
       "     0.0054041388565573235,\n",
       "     0.04668726547663605,\n",
       "     0.9939437971545786,\n",
       "     0.9998050945652971,\n",
       "     0.006749462185999434,\n",
       "     0.0001660639762104361,\n",
       "     0.009113941296123477,\n",
       "     0.055143810623271824,\n",
       "     0.07072334711361786,\n",
       "     0.998973354999276,\n",
       "     0.0034892418513176506,\n",
       "     0.00016998001932477187,\n",
       "     0.9995731871384811,\n",
       "     0.010362329913850348,\n",
       "     0.007584799681276243,\n",
       "     0.9588441284704942,\n",
       "     0.9995121205471379,\n",
       "     0.021862107919926054,\n",
       "     0.9989274608914575,\n",
       "     0.02024199644477045,\n",
       "     0.9996075444926485,\n",
       "     0.0013447834507276653,\n",
       "     0.996361932734252,\n",
       "     0.999855499621157,\n",
       "     0.9988084378484475,\n",
       "     0.9968578384990358,\n",
       "     0.9947977086921712,\n",
       "     0.008830047158847951,\n",
       "     0.9994861805558488,\n",
       "     0.99812229805152,\n",
       "     0.9994129863107457,\n",
       "     0.9919152652252888,\n",
       "     0.9863787390473707,\n",
       "     0.00157786254439414,\n",
       "     0.0011447682411731383,\n",
       "     0.9988692664941794,\n",
       "     0.013501077978819099,\n",
       "     0.9632484965151009,\n",
       "     0.9988114583461735,\n",
       "     0.9927862852561716,\n",
       "     0.9998539989013543,\n",
       "     0.001341296296286948,\n",
       "     0.9931895188119163,\n",
       "     0.0005925075026412524,\n",
       "     0.9998725114273158,\n",
       "     0.00018584385629872,\n",
       "     0.9992196254029182,\n",
       "     0.12142769082281529,\n",
       "     0.9939413266183228,\n",
       "     0.00013807435768734512,\n",
       "     0.9975877653265556,\n",
       "     0.9994996103970455,\n",
       "     0.0012040692920698634,\n",
       "     0.996829945527952,\n",
       "     0.03128727616737898,\n",
       "     0.9995230182185968,\n",
       "     0.9996003584710578,\n",
       "     0.00018161127383133245,\n",
       "     0.9982560345686762,\n",
       "     0.020232447530516392,\n",
       "     0.9979050702683843,\n",
       "     0.00014169495671899313,\n",
       "     0.0004430232370353099,\n",
       "     0.9480583155024459,\n",
       "     0.9997732052739964,\n",
       "     0.9988171791994355,\n",
       "     0.9998480638897934,\n",
       "     8.660228216173162e-05,\n",
       "     0.9991947279817357,\n",
       "     0.9936610212602077,\n",
       "     0.0004854906692385605,\n",
       "     0.006201870543970888,\n",
       "     0.9997553475892275,\n",
       "     0.9962054333877514,\n",
       "     0.9984627856633619,\n",
       "     0.9997510844496909,\n",
       "     0.9998979471831401,\n",
       "     0.9992187968874241,\n",
       "     0.9550655522918384,\n",
       "     0.00971281243824104,\n",
       "     0.06038264848195349,\n",
       "     0.0004960337811063037,\n",
       "     0.00021339757950706637,\n",
       "     0.9947837759511294],\n",
       "    'Best_Threshold': [0.7586576842750771,\n",
       "     0.7586576842750771,\n",
       "     0.6156785788838928,\n",
       "     0.6156776133205051,\n",
       "     0.4914574557115674,\n",
       "     0.5996598443541759,\n",
       "     0.7586576842750771,\n",
       "     0.7119975119492042,\n",
       "     0.6227988940244247,\n",
       "     0.5682289332585385,\n",
       "     0.7586576842750771,\n",
       "     0.6156792825597568,\n",
       "     0.7586571292329795,\n",
       "     0.6156776133205051,\n",
       "     0.6156769483111665,\n",
       "     0.835881891281252,\n",
       "     0.7586576842750771,\n",
       "     0.6156779886683341,\n",
       "     0.7040441568843022,\n",
       "     0.6781711065558306,\n",
       "     0.6156777129332512,\n",
       "     0.7586576842750771,\n",
       "     0.7586587950625204,\n",
       "     0.6156769483111665,\n",
       "     0.6156776133205051,\n",
       "     0.6156776133205051,\n",
       "     0.5996598443541759,\n",
       "     0.6156776133205051,\n",
       "     0.7586576842750771,\n",
       "     0.6156769483111665]},\n",
       "   {'f1_1': 0.9736842105263157,\n",
       "    'f1_0': 0.9473684210526315,\n",
       "    'f1_macro': 0.9605263157894737,\n",
       "    'f1_micro': 0.9649122807017544,\n",
       "    'prc_auc_1': 0.9986433679292381,\n",
       "    'prc_auc_0': 0.18341469181610146,\n",
       "    'precision_1': 0.9866666666666667,\n",
       "    'precision_0': 0.9230769230769231,\n",
       "    'macro_precision': 0.9548717948717949,\n",
       "    'micro_precision': 0.9649122807017544,\n",
       "    'recall_1': 0.961038961038961,\n",
       "    'recall_0': 0.972972972972973,\n",
       "    'macro_recall': 0.967005967005967,\n",
       "    'micro_recall': 0.9649122807017544,\n",
       "    'accuracy': 0.9649122807017544,\n",
       "    'roc_auc': 0.9971919971919971,\n",
       "    'cross_entropy': 0.072377156614087,\n",
       "    'fpr': [0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.02702702702702703,\n",
       "     0.02702702702702703,\n",
       "     0.05405405405405406,\n",
       "     0.05405405405405406,\n",
       "     1.0],\n",
       "    'tpr': [0.0,\n",
       "     0.012987012987012988,\n",
       "     0.935064935064935,\n",
       "     0.935064935064935,\n",
       "     0.961038961038961,\n",
       "     0.961038961038961,\n",
       "     1.0,\n",
       "     1.0],\n",
       "    'True_value': [1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1],\n",
       "    'Predict_value': [1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     1],\n",
       "    'Predict_prob_value': [0.7210143677630889,\n",
       "     0.0004714591012954791,\n",
       "     0.9424909521725146,\n",
       "     0.0024397162084582816,\n",
       "     0.000880962699675315,\n",
       "     0.9994146380996772,\n",
       "     0.995829860689799,\n",
       "     0.9998842870791649,\n",
       "     0.9834789250880277,\n",
       "     0.5023167199853541,\n",
       "     0.9900758300394933,\n",
       "     0.9992052793523415,\n",
       "     0.9986794122357954,\n",
       "     0.9274273269014134,\n",
       "     0.9984192481115062,\n",
       "     0.015434019862426929,\n",
       "     0.9994113794500554,\n",
       "     0.9641279431061083,\n",
       "     0.9983443400500096,\n",
       "     0.9982169065936813,\n",
       "     0.15101141238926746,\n",
       "     0.9924258381195353,\n",
       "     0.9998058356055216,\n",
       "     0.9978836265398053,\n",
       "     0.9965230004580952,\n",
       "     0.9998344022879391,\n",
       "     0.9350827217502891,\n",
       "     0.9660174953900548,\n",
       "     0.00014253511820293824,\n",
       "     0.0012835749424086047,\n",
       "     0.926120275781365,\n",
       "     0.9995649454353975,\n",
       "     0.0001420193938356327,\n",
       "     0.03217253136418213,\n",
       "     0.9998843188292437,\n",
       "     0.9966898149848724,\n",
       "     0.00018213830791021768,\n",
       "     0.9978866915991781,\n",
       "     0.0012977967207211142,\n",
       "     0.0021461803225603002,\n",
       "     0.8912792275936157,\n",
       "     0.04444393593212521,\n",
       "     0.0007989221419645532,\n",
       "     0.99977718764752,\n",
       "     0.9848109072856945,\n",
       "     0.9999668216168682,\n",
       "     0.8622448090003368,\n",
       "     0.9992532854004157,\n",
       "     0.005292149964891189,\n",
       "     0.9421526353922772,\n",
       "     0.9995274300950796,\n",
       "     0.9976985699087701,\n",
       "     0.9940947051230948,\n",
       "     9.709237796748993e-05,\n",
       "     0.0639985666992562,\n",
       "     0.9993013213847295,\n",
       "     0.9966709346267582,\n",
       "     0.9963958397109154,\n",
       "     0.9954632145795819,\n",
       "     0.5272993884928409,\n",
       "     0.9974913120602432,\n",
       "     0.9989376592589194,\n",
       "     0.08951580812977981,\n",
       "     0.9999593345823599,\n",
       "     0.9940973656850768,\n",
       "     0.9140317367154124,\n",
       "     0.015758165430531667,\n",
       "     0.0001342561491662918,\n",
       "     0.31788035423167843,\n",
       "     0.9387089444309374,\n",
       "     0.9984276825057529,\n",
       "     0.9943814247067256,\n",
       "     0.9000457459267521,\n",
       "     0.9868086592434454,\n",
       "     0.5970060913914617,\n",
       "     0.0783524580510642,\n",
       "     0.9990832806026982,\n",
       "     0.9964440395642543,\n",
       "     0.9974753837718281,\n",
       "     0.9998719299318298,\n",
       "     0.9991762774339626,\n",
       "     0.002829753277146429,\n",
       "     0.8318985382224625,\n",
       "     0.9965444050143117,\n",
       "     0.004867461439865008,\n",
       "     0.9439058954147472,\n",
       "     0.01733629200553634,\n",
       "     0.9990118434810807,\n",
       "     0.004549946854769361,\n",
       "     0.9994075848742706,\n",
       "     0.0004633342271472715,\n",
       "     0.014390456898783351,\n",
       "     0.9998431979379306,\n",
       "     0.9983516423889213,\n",
       "     0.9999711041799648,\n",
       "     0.9961504828845948,\n",
       "     0.9998152845302039,\n",
       "     0.9907361339780417,\n",
       "     0.0004923937136017887,\n",
       "     0.9998849757304134,\n",
       "     0.43499862547140256,\n",
       "     0.6840967728347971,\n",
       "     0.786410990737188,\n",
       "     6.841368880576942e-05,\n",
       "     0.0012099732435824411,\n",
       "     0.9511585126420454,\n",
       "     0.003777169152144842,\n",
       "     0.9999336852763778,\n",
       "     0.0004131524772144965,\n",
       "     0.999121977705442,\n",
       "     0.03871298903587669,\n",
       "     0.41612621372155695,\n",
       "     0.9999078365776358,\n",
       "     0.9883212277110046],\n",
       "    'Best_Threshold': [0.7586576842750771,\n",
       "     0.7586576842750771,\n",
       "     0.6156785788838928,\n",
       "     0.6156776133205051,\n",
       "     0.4914574557115674,\n",
       "     0.5996598443541759,\n",
       "     0.7586576842750771,\n",
       "     0.7119975119492042,\n",
       "     0.6227988940244247,\n",
       "     0.5682289332585385,\n",
       "     0.7586576842750771,\n",
       "     0.6156792825597568,\n",
       "     0.7586571292329795,\n",
       "     0.6156776133205051,\n",
       "     0.6156769483111665,\n",
       "     0.835881891281252,\n",
       "     0.7586576842750771,\n",
       "     0.6156779886683341,\n",
       "     0.7040441568843022,\n",
       "     0.6781711065558306,\n",
       "     0.6156777129332512,\n",
       "     0.7586576842750771,\n",
       "     0.7586587950625204,\n",
       "     0.6156769483111665,\n",
       "     0.6156776133205051,\n",
       "     0.6156776133205051,\n",
       "     0.5996598443541759,\n",
       "     0.6156776133205051,\n",
       "     0.7586576842750771,\n",
       "     0.6156769483111665]}]]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ID': 'Flow_0_2024-01-28 11:16:18_train',\n",
       "   'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "   'Set': 'train',\n",
       "   'Meta-Learner': 'XGBoost',\n",
       "   'Features': ['mean_radius',\n",
       "    'mean_texture',\n",
       "    'mean_perimeter',\n",
       "    'mean_area',\n",
       "    'mean_smoothness',\n",
       "    'mean_compactness',\n",
       "    'mean_concavity',\n",
       "    'mean_concave_points',\n",
       "    'mean_symmetry',\n",
       "    'mean_fractal_dimension',\n",
       "    'radius_error',\n",
       "    'texture_error',\n",
       "    'perimeter_error',\n",
       "    'area_error',\n",
       "    'smoothness_error',\n",
       "    'compactness_error',\n",
       "    'concavity_error',\n",
       "    'concave_points_error',\n",
       "    'symmetry_error',\n",
       "    'fractal_dimension_error',\n",
       "    'worst_radius',\n",
       "    'worst_texture',\n",
       "    'worst_perimeter',\n",
       "    'worst_area',\n",
       "    'worst_smoothness',\n",
       "    'worst_compactness',\n",
       "    'worst_concavity',\n",
       "    'worst_concave_points',\n",
       "    'worst_symmetry',\n",
       "    'worst_fractal_dimension'],\n",
       "   'FeatureSelection': 'None',\n",
       "   'Imbalanced': 'None',\n",
       "   'Decomposition': 'None',\n",
       "   'Standardization': 'None',\n",
       "   'Number_of_Data': {1: 208, 0: 133}},\n",
       "  {'ID': 'Flow_1_2024-01-28 11:16:18_vali',\n",
       "   'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "   'Set': 'vali',\n",
       "   'Meta-Learner': 'XGBoost',\n",
       "   'Features': ['mean_radius',\n",
       "    'mean_texture',\n",
       "    'mean_perimeter',\n",
       "    'mean_area',\n",
       "    'mean_smoothness',\n",
       "    'mean_compactness',\n",
       "    'mean_concavity',\n",
       "    'mean_concave_points',\n",
       "    'mean_symmetry',\n",
       "    'mean_fractal_dimension',\n",
       "    'radius_error',\n",
       "    'texture_error',\n",
       "    'perimeter_error',\n",
       "    'area_error',\n",
       "    'smoothness_error',\n",
       "    'compactness_error',\n",
       "    'concavity_error',\n",
       "    'concave_points_error',\n",
       "    'symmetry_error',\n",
       "    'fractal_dimension_error',\n",
       "    'worst_radius',\n",
       "    'worst_texture',\n",
       "    'worst_perimeter',\n",
       "    'worst_area',\n",
       "    'worst_smoothness',\n",
       "    'worst_compactness',\n",
       "    'worst_concavity',\n",
       "    'worst_concave_points',\n",
       "    'worst_symmetry',\n",
       "    'worst_fractal_dimension'],\n",
       "   'FeatureSelection': 'None',\n",
       "   'Imbalanced': 'None',\n",
       "   'Decomposition': 'None',\n",
       "   'Standardization': 'None',\n",
       "   'Number_of_Data': {1: 71, 0: 43}},\n",
       "  {'ID': 'Flow_2_2024-01-28 11:16:18_test',\n",
       "   'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "   'Set': 'test',\n",
       "   'Meta-Learner': 'XGBoost',\n",
       "   'Features': ['mean_radius',\n",
       "    'mean_texture',\n",
       "    'mean_perimeter',\n",
       "    'mean_area',\n",
       "    'mean_smoothness',\n",
       "    'mean_compactness',\n",
       "    'mean_concavity',\n",
       "    'mean_concave_points',\n",
       "    'mean_symmetry',\n",
       "    'mean_fractal_dimension',\n",
       "    'radius_error',\n",
       "    'texture_error',\n",
       "    'perimeter_error',\n",
       "    'area_error',\n",
       "    'smoothness_error',\n",
       "    'compactness_error',\n",
       "    'concavity_error',\n",
       "    'concave_points_error',\n",
       "    'symmetry_error',\n",
       "    'fractal_dimension_error',\n",
       "    'worst_radius',\n",
       "    'worst_texture',\n",
       "    'worst_perimeter',\n",
       "    'worst_area',\n",
       "    'worst_smoothness',\n",
       "    'worst_compactness',\n",
       "    'worst_concavity',\n",
       "    'worst_concave_points',\n",
       "    'worst_symmetry',\n",
       "    'worst_fractal_dimension'],\n",
       "   'FeatureSelection': 'None',\n",
       "   'Imbalanced': 'None',\n",
       "   'Decomposition': 'None',\n",
       "   'Standardization': 'None',\n",
       "   'Number_of_Data': {1: 78, 0: 36}}],\n",
       " [{'f1_1': 0.9976019184652278,\n",
       "   'f1_0': 0.9962264150943396,\n",
       "   'f1_macro': 0.9969141667797837,\n",
       "   'f1_micro': 0.9970674486803519,\n",
       "   'prc_auc_1': 0.9999304897156455,\n",
       "   'prc_auc_0': 0.22688833508898837,\n",
       "   'precision_1': 0.9952153110047847,\n",
       "   'precision_0': 1.0,\n",
       "   'macro_precision': 0.9976076555023923,\n",
       "   'micro_precision': 0.9970674486803519,\n",
       "   'recall_1': 1.0,\n",
       "   'recall_0': 0.9924812030075187,\n",
       "   'macro_recall': 0.9962406015037594,\n",
       "   'micro_recall': 0.9970674486803519,\n",
       "   'accuracy': 0.9970674486803519,\n",
       "   'roc_auc': 0.9998915558126084,\n",
       "   'cross_entropy': 0.024344045445792755,\n",
       "   'fpr': [0.0, 0.0, 0.0, 0.007518796992481203, 0.007518796992481203, 1.0],\n",
       "   'tpr': [0.0,\n",
       "    0.004807692307692308,\n",
       "    0.9855769230769231,\n",
       "    0.9855769230769231,\n",
       "    1.0,\n",
       "    1.0],\n",
       "   'True_value': [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_value': [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_prob_value': [[0.02075634778770199, 0.9792436522122979],\n",
       "    [0.029913651252332918, 0.9700863487476673],\n",
       "    [0.006436313419456606, 0.9935636865805435],\n",
       "    [0.00230956397593098, 0.997690436024069],\n",
       "    [0.004021345619472986, 0.9959786543805268],\n",
       "    [0.0050454047600409545, 0.9949545952399589],\n",
       "    [0.9997651362424028, 0.00023486097333069172],\n",
       "    [0.9997881247798539, 0.00021187564118157936],\n",
       "    [0.0013618280364700286, 0.9986381719635299],\n",
       "    [0.003049807634244937, 0.9969501923657548],\n",
       "    [0.9957885537091649, 0.00421144540025774],\n",
       "    [0.20645621901598166, 0.7935437809840183],\n",
       "    [0.9998515238747583, 0.0001484771952924707],\n",
       "    [0.028395753956205964, 0.9716042460437941],\n",
       "    [0.0009277055814048506, 0.9990722944185951],\n",
       "    [0.010526643032570393, 0.9894733569674297],\n",
       "    [0.999808639008322, 0.00019136039019875765],\n",
       "    [0.08220651722460186, 0.9177934827753982],\n",
       "    [0.913050840991393, 0.08694915826354895],\n",
       "    [0.008973839127508813, 0.991026160872491],\n",
       "    [0.007037688223582698, 0.992962311776417],\n",
       "    [0.9962291097728906, 0.0037708904250153886],\n",
       "    [0.0014253437648051677, 0.9985746562351949],\n",
       "    [0.0024646051644507854, 0.9975353948355491],\n",
       "    [0.014506645033002872, 0.985493354966997],\n",
       "    [0.00413492690724648, 0.9958650730927535],\n",
       "    [0.9514358657826635, 0.04856413244200281],\n",
       "    [0.9986380403568713, 0.0013619586419569437],\n",
       "    [0.02027871222654478, 0.9797212877734551],\n",
       "    [0.0048476995845526845, 0.9951523004154471],\n",
       "    [0.8146321912203989, 0.18536780704113234],\n",
       "    [0.007312435707520271, 0.9926875642924795],\n",
       "    [0.9998980151669955, 0.00010198372754386472],\n",
       "    [0.14194809723076363, 0.8580519025208839],\n",
       "    [0.9997309632679766, 0.00026903615576760254],\n",
       "    [0.9995317632256545, 0.00046824041814509237],\n",
       "    [0.0029369858533020753, 0.997063014146698],\n",
       "    [0.00041353611802165467, 0.9995864638819782],\n",
       "    [0.0028406512246292146, 0.9971593487753707],\n",
       "    [0.009295791034091424, 0.9907042089659084],\n",
       "    [0.008325674165757859, 0.9916743258342419],\n",
       "    [0.9904316283919095, 0.009568370622440862],\n",
       "    [0.0012015702155304406, 0.9987984297844695],\n",
       "    [0.020977272469701876, 0.979022727530298],\n",
       "    [0.0063895505621835895, 0.9936104494378165],\n",
       "    [0.001165860019516458, 0.9988341399804833],\n",
       "    [0.9995660796923609, 0.0004339221038306146],\n",
       "    [0.0014990266462494165, 0.9985009733537508],\n",
       "    [0.004400033618419127, 0.9955999663815809],\n",
       "    [0.0016163856584699235, 0.99838361434153],\n",
       "    [0.000120556986408867, 0.9998794430135912],\n",
       "    [0.00038405185492406833, 0.9996159481450758],\n",
       "    [0.032705549729009735, 0.9672944502709904],\n",
       "    [0.9802460270759027, 0.01975397484689034],\n",
       "    [0.0018947635107227257, 0.9981052364892772],\n",
       "    [0.997450337120092, 0.002549662418127153],\n",
       "    [0.9999051476540437, 9.485665962910042e-05],\n",
       "    [0.00024299243942260313, 0.9997570075605773],\n",
       "    [0.015560462054716019, 0.9844395379452837],\n",
       "    [0.01971080638524215, 0.9802891936147577],\n",
       "    [0.006279992353908495, 0.9937200076460915],\n",
       "    [0.9998015798226537, 0.00019842079725780994],\n",
       "    [0.0028200088865576334, 0.9971799911134424],\n",
       "    [0.001785561982398475, 0.9982144380176013],\n",
       "    [0.0008657257064724268, 0.9991342742935274],\n",
       "    [0.003254800777967723, 0.996745199222032],\n",
       "    [0.9998368957384753, 0.00016310534418719082],\n",
       "    [0.00020708066182815546, 0.9997929193381717],\n",
       "    [0.0037785220993089242, 0.9962214779006909],\n",
       "    [0.02366970531946501, 0.9763302946805349],\n",
       "    [0.004333080452214115, 0.9956669195477857],\n",
       "    [0.0011812485489486018, 0.9988187514510514],\n",
       "    [0.9982400708116719, 0.001759928669794863],\n",
       "    [0.0008832141707729052, 0.999116785829227],\n",
       "    [0.015377601287860242, 0.9846223987121399],\n",
       "    [0.9996480819892457, 0.0003519148694807967],\n",
       "    [0.0066313433712467135, 0.9933686566287532],\n",
       "    [0.0009162377963791041, 0.9990837622036209],\n",
       "    [0.00042831055989941757, 0.9995716894401007],\n",
       "    [0.004449671767350251, 0.9955503282326496],\n",
       "    [0.0011012812691835656, 0.9988987187308161],\n",
       "    [0.0011086912253659717, 0.998891308774634],\n",
       "    [0.9987297290954991, 0.0012702684985843311],\n",
       "    [0.9958840311979016, 0.00411597164263208],\n",
       "    [4.321628876123862e-05, 0.9999567837112388],\n",
       "    [0.00039867499417058517, 0.9996013250058293],\n",
       "    [0.0016346289681428176, 0.9983653710318573],\n",
       "    [0.0015161687912209128, 0.9984838312087787],\n",
       "    [0.27996861551309, 0.7200313844869101],\n",
       "    [2.6026081882768447e-05, 0.9999739739181174],\n",
       "    [0.8946610828014357, 0.10533891527383096],\n",
       "    [0.07653635462985041, 0.9234636453701495],\n",
       "    [0.999161531661185, 0.000838472042762438],\n",
       "    [0.9998131457365141, 0.00018685708558724944],\n",
       "    [0.0012677980680446596, 0.9987322019319553],\n",
       "    [0.004363534284187539, 0.9956364657158123],\n",
       "    [0.02354232907877143, 0.9764576709212285],\n",
       "    [0.055599280978182605, 0.9444007190218175],\n",
       "    [0.0003811391980516755, 0.9996188608019484],\n",
       "    [0.9925933592340471, 0.00740664042252759],\n",
       "    [0.0006914868195622331, 0.9993085131804378],\n",
       "    [0.0060292515324214275, 0.9939707484675786],\n",
       "    [0.9997813398561302, 0.0002186614845863683],\n",
       "    [0.0024870129279698167, 0.99751298707203],\n",
       "    [0.9997759117349417, 0.00022408739776402597],\n",
       "    [0.012855280367128567, 0.9871447196328713],\n",
       "    [0.9477592221565775, 0.052240777765812124],\n",
       "    [0.0008566908832231799, 0.9991433091167768],\n",
       "    [0.001392722645197733, 0.9986072773548021],\n",
       "    [0.0015167119239017028, 0.9984832880760983],\n",
       "    [0.9860821687138261, 0.01391783034709038],\n",
       "    [0.9787210885320958, 0.021278915317370806],\n",
       "    [0.266003050926803, 0.7339969490731971],\n",
       "    [0.9981538412457706, 0.0018461586543065196],\n",
       "    [0.00038156807756144836, 0.9996184319224386],\n",
       "    [0.01326365840664478, 0.9867363415933551],\n",
       "    [0.9774337414289197, 0.022566256273817895],\n",
       "    [0.0050579318282934225, 0.9949420681717065],\n",
       "    [0.007388132200916057, 0.9926118677990837],\n",
       "    [0.0004865738359288493, 0.9995134261640712],\n",
       "    [0.0032422331199980147, 0.9967577668800017],\n",
       "    [0.03418986253680571, 0.9658101374631944],\n",
       "    [0.9948653145311371, 0.005134686671821049],\n",
       "    [0.9998408870705243, 0.0001591142420583276],\n",
       "    [0.010847832576101142, 0.9891521674238989],\n",
       "    [0.01049949606023661, 0.9895005039397634],\n",
       "    [0.004920648965894053, 0.9950793510341058],\n",
       "    [0.9993562821545487, 0.0006437188534139642],\n",
       "    [0.9784357458412118, 0.021564252637627825],\n",
       "    [0.9963636892948552, 0.0036363107488003635],\n",
       "    [0.986968068717384, 0.01303193050651374],\n",
       "    [0.058757405182030056, 0.9412425948179701],\n",
       "    [0.9901127244612646, 0.009887274560846536],\n",
       "    [0.007122390177891644, 0.9928776098221083],\n",
       "    [0.9984649167093842, 0.0015350821904910516],\n",
       "    [0.0014386144487649106, 0.9985613855512351],\n",
       "    [0.9766781978721338, 0.023321802236520486],\n",
       "    [0.9989141317201061, 0.001085868270192543],\n",
       "    [0.07832379105947587, 0.921676208940524],\n",
       "    [0.00014365520629386157, 0.9998563447937061],\n",
       "    [0.055035671820359774, 0.9449643281796403],\n",
       "    [0.9999115087969342, 8.849053755821845e-05],\n",
       "    [0.9918753101686892, 0.008124690353239341],\n",
       "    [0.9998642008638325, 0.00013579764799176566],\n",
       "    [0.0004206582663121791, 0.9995793417336877],\n",
       "    [0.04744692341764029, 0.9525530765823597],\n",
       "    [0.006368868086501466, 0.9936311319134986],\n",
       "    [0.003947202039028447, 0.9960527979609715],\n",
       "    [0.004452321843754218, 0.9955476781562458],\n",
       "    [0.012045438013819519, 0.9879545619861805],\n",
       "    [0.9999128071121773, 8.719317352550252e-05],\n",
       "    [0.02918037478189963, 0.9708196252181003],\n",
       "    [0.9995274437063052, 0.00047255660316560465],\n",
       "    [0.9983577234394985, 0.0016422739838423761],\n",
       "    [0.016368025387202157, 0.9836319746127978],\n",
       "    [0.9997432826198109, 0.00025671872090552366],\n",
       "    [0.998899608044383, 0.0011003928845142615],\n",
       "    [0.9930579291975673, 0.006942070887803873],\n",
       "    [0.9932357279964117, 0.006764276425430288],\n",
       "    [0.0023669960924124537, 0.9976330039075874],\n",
       "    [0.6697680754533267, 0.3302319250433786],\n",
       "    [0.9878697212004754, 0.012130281182158188],\n",
       "    [0.9895954665868191, 0.010404532986324839],\n",
       "    [0.9988148797243093, 0.0011851192948916062],\n",
       "    [0.0010858993946886895, 0.9989141006053113],\n",
       "    [0.006841698997263588, 0.9931583010027364],\n",
       "    [0.9800188078221194, 0.01998118965263836],\n",
       "    [0.0014766813153113223, 0.9985233186846887],\n",
       "    [0.0035135276253081115, 0.9964864723746918],\n",
       "    [0.9910366454416591, 0.00896335802751729],\n",
       "    [0.00832913773773479, 0.991670862262265],\n",
       "    [0.001273635271976036, 0.9987263647280239],\n",
       "    [0.0013740664273840415, 0.9986259335726159],\n",
       "    [0.7754634598234722, 0.2245365381897063],\n",
       "    [0.0016641341575605883, 0.9983358658424393],\n",
       "    [0.007121992282622784, 0.9928780077173774],\n",
       "    [0.999112298107987, 0.0008877011197912867],\n",
       "    [0.0008247913100760076, 0.999175208689924],\n",
       "    [0.9310911842540087, 0.06890881649104949],\n",
       "    [0.015009793951356784, 0.9849902060486432],\n",
       "    [0.006945191120183787, 0.9930548088798161],\n",
       "    [0.0017684128038996832, 0.9982315871961002],\n",
       "    [0.9970732680233731, 0.0029267302080840437],\n",
       "    [0.9998425764109721, 0.0001574222735347449],\n",
       "    [0.002214051639287442, 0.9977859483607124],\n",
       "    [0.995294265261541, 0.004705735910373218],\n",
       "    [0.0014078684369172548, 0.9985921315630828],\n",
       "    [0.9998451306442926, 0.0001548711582045244],\n",
       "    [0.03414745123572838, 0.9658525487642715],\n",
       "    [0.0031676529010741185, 0.9968323470989258],\n",
       "    [0.9327047936459623, 0.06729520770445552],\n",
       "    [0.013288625032108285, 0.9867113749678917],\n",
       "    [0.022080179484739466, 0.9779198205152604],\n",
       "    [0.9885146174688891, 0.011485385346421443],\n",
       "    [0.01385030373376223, 0.9861496962662378],\n",
       "    [0.10848465317133513, 0.891515346828665],\n",
       "    [0.9994801941860191, 0.0005198038649942364],\n",
       "    [0.001235608769809441, 0.9987643912301905],\n",
       "    [0.04258548754509816, 0.9574145124549017],\n",
       "    [0.993714190062063, 0.0062858101911402835],\n",
       "    [0.004478773333088117, 0.9955212266669117],\n",
       "    [0.00693233216405116, 0.9930676678359488],\n",
       "    [0.9111124977578208, 0.0888875027388846],\n",
       "    [0.02009435445957751, 0.9799056455404224],\n",
       "    [0.00018834906934828144, 0.9998116509306517],\n",
       "    [0.9995297632796343, 0.0004702386625611884],\n",
       "    [0.030088944780890452, 0.9699110552191097],\n",
       "    [0.004491505379522147, 0.9955084946204777],\n",
       "    [0.0008418043659662438, 0.9991581956340336],\n",
       "    [0.0009213355339456844, 0.9990786644660544],\n",
       "    [0.9991560633680798, 0.0008439388738852148],\n",
       "    [0.9897958860932754, 0.01020411670069238],\n",
       "    [0.0021042403583081916, 0.9978957596416916],\n",
       "    [0.0054239138776692, 0.9945760861223308],\n",
       "    [0.9997517526449277, 0.00024824579510709043],\n",
       "    [0.09710210907769727, 0.902897891419008],\n",
       "    [0.01551040292930053, 0.9844895970706993],\n",
       "    [0.0015722877100663175, 0.9984277122899338],\n",
       "    [0.996003949652567, 0.00399605144561736],\n",
       "    [0.006787349275349266, 0.9932126507246506],\n",
       "    [0.0032109894004357835, 0.9967890105995642],\n",
       "    [0.0008339829015997089, 0.9991660170984002],\n",
       "    [0.0368431865114301, 0.9631568134885699],\n",
       "    [0.003181414101424804, 0.9968185858985751],\n",
       "    [0.009121252642703732, 0.9908787473572963],\n",
       "    [0.9998344678960273, 0.00016553133466147172],\n",
       "    [0.9994767489237099, 0.000523250378768397],\n",
       "    [0.9616389996878535, 0.03836099590776699],\n",
       "    [0.9980647061188432, 0.001935293689071385],\n",
       "    [6.201840992040575e-05, 0.9999379815900796],\n",
       "    [0.9619977569838161, 0.0380022434139363],\n",
       "    [0.9995937908015924, 0.0004062098838028569],\n",
       "    [0.0005563368644246373, 0.9994436631355755],\n",
       "    [0.9995373809956843, 0.00046261624042204263],\n",
       "    [0.08913861845097022, 0.9108613815490298],\n",
       "    [0.9998280142146869, 0.00017198417878162755],\n",
       "    [0.9987420241952659, 0.0012579752915365052],\n",
       "    [0.9998022803815811, 0.00019772191277082752],\n",
       "    [0.7436610392315155, 0.25633896101683695],\n",
       "    [0.0022850064488667424, 0.997714993551133],\n",
       "    [0.02688433720640805, 0.973115662793592],\n",
       "    [0.9946816422913801, 0.005318357173109302],\n",
       "    [0.9036211627793995, 0.09637883765521751],\n",
       "    [0.9891001400487998, 0.010899862997401326],\n",
       "    [0.9892663378427345, 0.010733662269800206],\n",
       "    [0.9949825339492903, 0.005017465988621688],\n",
       "    [0.9363002195674587, 0.06369977940808627],\n",
       "    [0.982453863467977, 0.01754613576174165],\n",
       "    [0.007553673567676473, 0.9924463264323236],\n",
       "    [0.0019461152800678602, 0.9980538847199321],\n",
       "    [0.0007921366335222736, 0.9992078633664776],\n",
       "    [0.00174804906333441, 0.9982519509366655],\n",
       "    [0.9978056576220004, 0.0021943476884786184],\n",
       "    [0.0008275600643527719, 0.9991724399356471],\n",
       "    [0.027856594545085423, 0.9721434054549147],\n",
       "    [0.004997242563677748, 0.9950027574363222],\n",
       "    [0.04539458100758668, 0.9546054189924134],\n",
       "    [0.9988273254538768, 0.0011726721557284259],\n",
       "    [0.9991810243889686, 0.0008189735640620031],\n",
       "    [0.01475806009730292, 0.985241939902697],\n",
       "    [0.005446601075878261, 0.9945533989241215],\n",
       "    [0.9446945888340401, 0.0553054109176073],\n",
       "    [0.9975526068085006, 0.0024473936353328965],\n",
       "    [0.04530149470822363, 0.9546985052917764],\n",
       "    [0.0072063945723510655, 0.9927936054276488],\n",
       "    [0.038402931973125505, 0.9615970680268746],\n",
       "    [0.9994356601493494, 0.0005643400786306467],\n",
       "    [0.0003855258606578387, 0.9996144741393421],\n",
       "    [0.9998160380131432, 0.00018396388539657595],\n",
       "    [0.9993727933736459, 0.0006272086092949598],\n",
       "    [0.00013209657894728646, 0.9998679034210526],\n",
       "    [0.005023143778931236, 0.9949768562210687],\n",
       "    [0.9999020783606469, 9.792150887097541e-05],\n",
       "    [0.9989048778964593, 0.0010951199285142675],\n",
       "    [0.99986701465121, 0.00013298675935560227],\n",
       "    [0.9998869513733368, 0.0001130464841363638],\n",
       "    [0.999806386131126, 0.0001936144955765703],\n",
       "    [0.00018077972675638229, 0.9998192202732437],\n",
       "    [0.0014354674928197112, 0.9985645325071801],\n",
       "    [0.11897538241822245, 0.8810246175817776],\n",
       "    [0.0027430715970361676, 0.997256928402964],\n",
       "    [0.9991497697240267, 0.0008502320969028118],\n",
       "    [0.005067997691316293, 0.9949320023086836],\n",
       "    [0.0010626705037409877, 0.9989373294962589],\n",
       "    [0.999085641907103, 0.0009143559081694379],\n",
       "    [0.0023579272365494564, 0.9976420727634506],\n",
       "    [0.04035756318221608, 0.9596424368177839],\n",
       "    [0.0007805252567482506, 0.9992194747432516],\n",
       "    [0.000955639730253665, 0.9990443602697464],\n",
       "    [0.0007670272255258583, 0.9992329727744741],\n",
       "    [0.9823018436974846, 0.017698155091795984],\n",
       "    [0.0008930690800515038, 0.9991069309199485],\n",
       "    [0.9574675074456569, 0.04253248865054931],\n",
       "    [0.9957530800693257, 0.004246919503817921],\n",
       "    [0.9875454888166159, 0.012454511121295883],\n",
       "    [0.9734362570064103, 0.0265637392450161],\n",
       "    [0.0005951126153786085, 0.9994048873846214],\n",
       "    [0.00012890447575116814, 0.9998710955242487],\n",
       "    [0.9871664178475241, 0.01283358191188425],\n",
       "    [6.071188766624269e-05, 0.9999392881123337],\n",
       "    [0.9998460174769926, 0.00015398292075966192],\n",
       "    [0.9998639040498826, 0.0001360958521346695],\n",
       "    [0.9985226208751387, 0.0014773768581579653],\n",
       "    [0.007417877832780364, 0.9925821221672195],\n",
       "    [0.00017316351241059754, 0.9998268364875894],\n",
       "    [0.010964071482075064, 0.989035928517925],\n",
       "    [0.9911253352329753, 0.00887466287333555],\n",
       "    [0.9473033616100516, 0.05269663748966973],\n",
       "    [0.0011203383403643268, 0.9988796616596356],\n",
       "    [0.9998478376601326, 0.00015216104086645843],\n",
       "    [0.010063636388437387, 0.9899363636115626],\n",
       "    [0.9979483341204347, 0.002051668033248713],\n",
       "    [0.9690026342900239, 0.030997362434825235],\n",
       "    [0.0011275639032528623, 0.9988724360967469],\n",
       "    [0.045283934800537586, 0.9547160651994625],\n",
       "    [0.9855804308057365, 0.014419569316499386],\n",
       "    [0.0003680950900169545, 0.999631904909983],\n",
       "    [0.999432335476789, 0.0005676644756745779],\n",
       "    [0.7857161527106193, 0.21428385026961286],\n",
       "    [0.9994282672920737, 0.000571731188706232],\n",
       "    [0.998586834108668, 0.0014131646670306785],\n",
       "    [0.003533864382955877, 0.996466135617044],\n",
       "    [0.0027876711249156783, 0.9972123288750842],\n",
       "    [0.1711648097578437, 0.8288351902421562],\n",
       "    [0.010342752785037069, 0.989657247214963],\n",
       "    [0.00047488034760582136, 0.9995251196523942],\n",
       "    [0.003014925916021373, 0.9969850740839785],\n",
       "    [0.017772372324663846, 0.9822276276753362],\n",
       "    [0.0007693566279722872, 0.9992306433720278],\n",
       "    [0.0008223256088674389, 0.9991776743911326],\n",
       "    [0.002102419606440122, 0.9978975803935597],\n",
       "    [0.9683560581924227, 0.031643939308528615],\n",
       "    [0.007533430104960758, 0.9924665698950391],\n",
       "    [0.00010676508239684615, 0.9998932349176033],\n",
       "    [0.11889026219243766, 0.881109737683386],\n",
       "    [0.04841632457005085, 0.9515836754299494],\n",
       "    [0.9199574381928423, 0.08004256006868893],\n",
       "    [0.00013133404797915544, 0.9998686659520207],\n",
       "    [0.0034561127480453855, 0.9965438872519545],\n",
       "    [0.005774356516978321, 0.9942256434830214],\n",
       "    [0.0356975052792328, 0.9643024947207673]],\n",
       "   'Best_Threshold': [0.901637755229649,\n",
       "    0.384330998802136,\n",
       "    0.5155062297763521,\n",
       "    0.7586576842750771,\n",
       "    0.38433245166349533,\n",
       "    0.5474883671871175,\n",
       "    0.7586576842750771,\n",
       "    0.6156787604716543,\n",
       "    0.5543422900410034,\n",
       "    0.7586576842750771,\n",
       "    0.6961493291169474,\n",
       "    0.67029114071128,\n",
       "    0.7040441568843022,\n",
       "    0.7469818264739659,\n",
       "    0.6156776133205051,\n",
       "    0.8470242278388741,\n",
       "    0.7040441568843022,\n",
       "    0.5543422900410034,\n",
       "    0.6156776133205051,\n",
       "    0.7377971730573245,\n",
       "    0.6079997455476859,\n",
       "    0.8470242278388741,\n",
       "    0.3843323638862662,\n",
       "    0.5147356489025322,\n",
       "    0.6156776133205051,\n",
       "    0.6156775611714203,\n",
       "    0.6116516584745381,\n",
       "    0.8470242278388741,\n",
       "    0.24135092784756415,\n",
       "    0.24135092784756415]},\n",
       "  {'f1_1': 1.0,\n",
       "   'f1_0': 1.0,\n",
       "   'f1_macro': 1.0,\n",
       "   'f1_micro': 1.0,\n",
       "   'prc_auc_1': 1.0,\n",
       "   'prc_auc_0': 0.2181270468155756,\n",
       "   'precision_1': 1.0,\n",
       "   'precision_0': 1.0,\n",
       "   'macro_precision': 1.0,\n",
       "   'micro_precision': 1.0,\n",
       "   'recall_1': 1.0,\n",
       "   'recall_0': 1.0,\n",
       "   'macro_recall': 1.0,\n",
       "   'micro_recall': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'roc_auc': 1.0,\n",
       "   'cross_entropy': 0.013475875593430728,\n",
       "   'fpr': [0.0, 0.0, 0.0, 1.0],\n",
       "   'tpr': [0.0, 0.014084507042253521, 1.0, 1.0],\n",
       "   'True_value': [0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0],\n",
       "   'Predict_value': [0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0],\n",
       "   'Predict_prob_value': [[0.989091719875716, 0.0109082780695537],\n",
       "    [0.0004302576625165678, 0.9995697423374834],\n",
       "    [0.9997992044487608, 0.0002007968929258649],\n",
       "    [0.0062249666332513005, 0.9937750333667486],\n",
       "    [0.0007367524417076475, 0.9992632475582923],\n",
       "    [0.0009622383560295687, 0.9990377616439704],\n",
       "    [0.9988800160816526, 0.0011199823782698036],\n",
       "    [0.9743124817921021, 0.025687515673924535],\n",
       "    [0.003229256943865693, 0.9967707430561341],\n",
       "    [0.0030892381365127445, 0.9969107618634873],\n",
       "    [0.9235522457859345, 0.07644775135800952],\n",
       "    [0.014640536006745464, 0.9853594639932547],\n",
       "    [0.998497058398295, 0.0015029383760303639],\n",
       "    [0.9997484184767892, 0.00025158032995381584],\n",
       "    [0.9958739487704324, 0.00412604787729112],\n",
       "    [0.002767073599882069, 0.9972329264001177],\n",
       "    [0.0017145030701592701, 0.9982854969298406],\n",
       "    [0.9998488559521139, 0.00015114597358961747],\n",
       "    [0.0022524845265595637, 0.9977475154734404],\n",
       "    [0.999580550835839, 0.00041944860779288866],\n",
       "    [6.965056984606552e-05, 0.999930349430154],\n",
       "    [0.9999141567262294, 8.584131799313208e-05],\n",
       "    [0.9998446024102066, 0.00015539539342441234],\n",
       "    [0.00037841564926749025, 0.9996215843507327],\n",
       "    [0.999783436983585, 0.0002165661877623039],\n",
       "    [0.9977761253489456, 0.0022238713138152044],\n",
       "    [0.9846091850024806, 0.015390816735987987],\n",
       "    [0.9205137741057399, 0.07948622645305349],\n",
       "    [0.0010855381205765306, 0.9989144618794232],\n",
       "    [0.9885573111176771, 0.011442692700745292],\n",
       "    [0.02578948638948607, 0.974210513610514],\n",
       "    [0.0007367768163480831, 0.9992632231836519],\n",
       "    [0.00539670951379397, 0.9946032904862059],\n",
       "    [0.0005678524861187952, 0.9994321475138812],\n",
       "    [0.9077879122793309, 0.09221208961435827],\n",
       "    [0.000946287387274232, 0.9990537126127258],\n",
       "    [0.0005004534605171804, 0.9994995465394827],\n",
       "    [0.0007675953766397771, 0.9992324046233603],\n",
       "    [0.0008154073303831071, 0.9991845926696169],\n",
       "    [0.9590455970105158, 0.04095440357932182],\n",
       "    [0.8553314585987475, 0.14466854239466323],\n",
       "    [0.9997776332925721, 0.00022236773770351962],\n",
       "    [0.0011691659698734385, 0.9988308340301264],\n",
       "    [0.09135969063589842, 0.9086403093641017],\n",
       "    [0.008261884797477715, 0.9917381152025222],\n",
       "    [3.716213251343155e-05, 0.9999628378674866],\n",
       "    [0.001564332004798488, 0.9984356679952014],\n",
       "    [0.9992142421147864, 0.0007857543869331607],\n",
       "    [0.0004634403600273189, 0.9995365596399727],\n",
       "    [0.00045411450436623545, 0.9995458854956337],\n",
       "    [0.93854269409443, 0.06145730497424746],\n",
       "    [0.016811260796663625, 0.9831887392033365],\n",
       "    [0.9998524421213989, 0.00014755912715543347],\n",
       "    [0.0037752216107404353, 0.9962247783892596],\n",
       "    [0.006258593772215925, 0.993741406227784],\n",
       "    [5.5967088715265977e-05, 0.9999440329112848],\n",
       "    [0.9974614436471997, 0.002538552594525673],\n",
       "    [0.9965289349596518, 0.003471060752869127],\n",
       "    [0.999593564114872, 0.0004064378312041268],\n",
       "    [0.07123276309935135, 0.9287672369006487],\n",
       "    [0.9785750626574484, 0.02142493945354938],\n",
       "    [0.0003889393866644439, 0.9996110606133356],\n",
       "    [0.0014048451910738916, 0.9985951548089259],\n",
       "    [0.046401966172834284, 0.9535980338271658],\n",
       "    [0.9995766255427913, 0.00042337330275695736],\n",
       "    [0.01816555076866253, 0.9818344492313374],\n",
       "    [0.00112125654150504, 0.9988787434584948],\n",
       "    [0.0013253655428055483, 0.9986746344571944],\n",
       "    [0.9825932976916294, 0.017406697558625655],\n",
       "    [0.0011449321664736515, 0.9988550678335263],\n",
       "    [0.015020563909949452, 0.9849794360900506],\n",
       "    [0.986099443386461, 0.013900555868480834],\n",
       "    [6.0913955576210226e-05, 0.9999390860444237],\n",
       "    [0.0028952088581439095, 0.9971047911418558],\n",
       "    [0.9846115181939604, 0.015388483829726],\n",
       "    [0.9864066601781646, 0.013593340508685785],\n",
       "    [0.9998232926224534, 0.00017670978734382937],\n",
       "    [0.0157036103322435, 0.9842963896677566],\n",
       "    [0.0017941951932322383, 0.9982058048067677],\n",
       "    [0.0046943384531125155, 0.9953056615468874],\n",
       "    [0.976753556857446, 0.023246442087055057],\n",
       "    [0.9998135595749764, 0.0001864379900031793],\n",
       "    [0.9985939743674151, 0.0014060253221440079],\n",
       "    [0.9995547355988602, 0.00044526338978151153],\n",
       "    [0.9997410416786165, 0.00025895570785945606],\n",
       "    [0.0005843523884267007, 0.9994156476115731],\n",
       "    [0.0010749875516231813, 0.9989250124483767],\n",
       "    [0.008450761975231773, 0.9915492380247681],\n",
       "    [0.0001321340058862641, 0.9998678659941137],\n",
       "    [0.0009847021674242778, 0.9990152978325757],\n",
       "    [0.0005000506252326209, 0.9994999493747674],\n",
       "    [0.007365917715385643, 0.9926340822846146],\n",
       "    [0.0017785427334202173, 0.9982214572665795],\n",
       "    [0.9834599074051764, 0.016540091663501108],\n",
       "    [0.0005971989030166933, 0.9994028010969832],\n",
       "    [0.003746068396611347, 0.9962539316033887],\n",
       "    [0.0009143252879726614, 0.9990856747120271],\n",
       "    [0.8519151615714109, 0.14808483569670955],\n",
       "    [0.024398725645155692, 0.9756012743548443],\n",
       "    [0.0005948390777728905, 0.9994051609222271],\n",
       "    [0.9920861464132215, 0.007913849861488171],\n",
       "    [0.0035530398665632127, 0.9964469601334366],\n",
       "    [0.0007658534487291548, 0.9992341465512709],\n",
       "    [0.00041283203113204114, 0.9995871679688679],\n",
       "    [0.004450408128913449, 0.9955495918710864],\n",
       "    [0.0993474483324388, 0.9006525516675611],\n",
       "    [0.0004068966964558863, 0.9995931033035442],\n",
       "    [0.04310890480755306, 0.9568910951924468],\n",
       "    [0.0011027220149434868, 0.9988972779850565],\n",
       "    [3.957230015037375e-05, 0.9999604276998497],\n",
       "    [0.0008992270610790848, 0.999100772938921],\n",
       "    [0.03229474437321659, 0.9677052556267836],\n",
       "    [0.0010651177341833582, 0.9989348822658167],\n",
       "    [0.9998999854014861, 0.00010001595863278627]],\n",
       "   'Best_Threshold': [0.901637755229649,\n",
       "    0.384330998802136,\n",
       "    0.5155062297763521,\n",
       "    0.7586576842750771,\n",
       "    0.38433245166349533,\n",
       "    0.5474883671871175,\n",
       "    0.7586576842750771,\n",
       "    0.6156787604716543,\n",
       "    0.5543422900410034,\n",
       "    0.7586576842750771,\n",
       "    0.6961493291169474,\n",
       "    0.67029114071128,\n",
       "    0.7040441568843022,\n",
       "    0.7469818264739659,\n",
       "    0.6156776133205051,\n",
       "    0.8470242278388741,\n",
       "    0.7040441568843022,\n",
       "    0.5543422900410034,\n",
       "    0.6156776133205051,\n",
       "    0.7377971730573245,\n",
       "    0.6079997455476859,\n",
       "    0.8470242278388741,\n",
       "    0.3843323638862662,\n",
       "    0.5147356489025322,\n",
       "    0.6156776133205051,\n",
       "    0.6156775611714203,\n",
       "    0.6116516584745381,\n",
       "    0.8470242278388741,\n",
       "    0.24135092784756415,\n",
       "    0.24135092784756415]},\n",
       "  {'f1_1': 0.9936305732484078,\n",
       "   'f1_0': 0.9859154929577464,\n",
       "   'f1_macro': 0.9897730331030771,\n",
       "   'f1_micro': 0.9912280701754386,\n",
       "   'prc_auc_1': 0.9999999999999999,\n",
       "   'prc_auc_0': 0.1777567027375918,\n",
       "   'precision_1': 0.9873417721518988,\n",
       "   'precision_0': 1.0,\n",
       "   'macro_precision': 0.9936708860759493,\n",
       "   'micro_precision': 0.9912280701754386,\n",
       "   'recall_1': 1.0,\n",
       "   'recall_0': 0.9722222222222222,\n",
       "   'macro_recall': 0.9861111111111112,\n",
       "   'micro_recall': 0.9912280701754386,\n",
       "   'accuracy': 0.9912280701754386,\n",
       "   'roc_auc': 1.0,\n",
       "   'cross_entropy': 0.04147971320051599,\n",
       "   'fpr': [0.0, 0.0, 0.0, 1.0],\n",
       "   'tpr': [0.0, 0.01282051282051282, 1.0, 1.0],\n",
       "   'True_value': [1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_value': [1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_prob_value': [[0.0013819229815727758, 0.9986180770184272],\n",
       "    [0.001165679210758481, 0.9988343207892415],\n",
       "    [0.9477481890602416, 0.05225181522578241],\n",
       "    [0.9970298318498079, 0.0029701695665785262],\n",
       "    [0.056373827847445816, 0.9436261721525541],\n",
       "    [0.99508395495382, 0.0049160459251155275],\n",
       "    [0.8378762409848638, 0.16212375802172538],\n",
       "    [0.999923038342203, 7.696113780861199e-05],\n",
       "    [0.012278331255216926, 0.9877216687447833],\n",
       "    [0.0007328380145854383, 0.9992671619854147],\n",
       "    [0.044483444120748235, 0.9555165558792517],\n",
       "    [0.002070930715030563, 0.9979290692849694],\n",
       "    [0.012408017769214718, 0.9875919822307854],\n",
       "    [0.9995633472503184, 0.0004366553253706661],\n",
       "    [0.005731001146656369, 0.9942689988533435],\n",
       "    [0.006306704557184153, 0.9936932954428158],\n",
       "    [0.0006022206422376088, 0.9993977793577623],\n",
       "    [0.006868993710158251, 0.9931310062898417],\n",
       "    [0.04629329656138472, 0.9537067034386154],\n",
       "    [0.004772101774483243, 0.9952278982255167],\n",
       "    [0.999532656805636, 0.00046734145492516343],\n",
       "    [0.003061757427168983, 0.996938242572831],\n",
       "    [0.006765590440154809, 0.993234409559845],\n",
       "    [0.9989568373688384, 0.001043164734398335],\n",
       "    [0.028471287029799064, 0.9715287129702012],\n",
       "    [0.00048456869258168466, 0.9995154313074184],\n",
       "    [0.004706143103151098, 0.9952938568968488],\n",
       "    [0.9986444715555861, 0.0013555288673895284],\n",
       "    [0.9992144145390771, 0.0007855863417990432],\n",
       "    [0.9971768072234304, 0.0028231927513463514],\n",
       "    [0.9979710636816518, 0.0020289362174550104],\n",
       "    [0.9991606251177159, 0.0008393740227507412],\n",
       "    [0.06355319616724933, 0.9364468038327508],\n",
       "    [0.0015424617322934233, 0.9984575382677066],\n",
       "    [0.003047171299546503, 0.9969528287004533],\n",
       "    [0.9995600117052156, 0.00043999266326924226],\n",
       "    [0.005835311895739958, 0.99416468810426],\n",
       "    [0.007604148257670346, 0.9923958517423296],\n",
       "    [0.9209631866598872, 0.07903681371264205],\n",
       "    [0.007785206407373902, 0.9922147935926261],\n",
       "    [0.9303797772918949, 0.06962022134216536],\n",
       "    [0.7241094216204987, 0.2758905763926796],\n",
       "    [0.03709969256205613, 0.9629003074379437],\n",
       "    [0.0053649042032445785, 0.9946350957967555],\n",
       "    [0.017735590758930966, 0.9822644092410692],\n",
       "    [0.999366491226401, 0.0006335097262643623],\n",
       "    [0.9999101949602363, 8.980403956204043e-05],\n",
       "    [0.007741746964150457, 0.9922582530358495],\n",
       "    [0.013232499372948582, 0.9867675006270513],\n",
       "    [0.007187557312794066, 0.9928124426872059],\n",
       "    [0.006970525974218616, 0.9930294740257815],\n",
       "    [0.0009497475013151603, 0.9990502524986848],\n",
       "    [0.9758035139177699, 0.024196487432647868],\n",
       "    [0.9998500981203665, 0.00014990044869524934],\n",
       "    [0.9873304013106053, 0.01266959633780505],\n",
       "    [0.35853246783702897, 0.6414675331563816],\n",
       "    [0.0007383481890724205, 0.9992616518109276],\n",
       "    [0.017577639538304136, 0.982422360461696],\n",
       "    [0.004373226129118428, 0.9956267738708815],\n",
       "    [0.0032587870174222164, 0.9967412129825777],\n",
       "    [0.0021968568214618253, 0.9978031431785382],\n",
       "    [0.9994769744365832, 0.0005230268110010081],\n",
       "    [0.0028920377918195965, 0.9971079622081802],\n",
       "    [0.024455725437879248, 0.9755442745621209],\n",
       "    [0.011501824779033462, 0.9884981752209664],\n",
       "    [0.9987110209425855, 0.0012889780911673142],\n",
       "    [0.0007266850638835914, 0.9992733149361163],\n",
       "    [0.0956876744221235, 0.9043123255778768],\n",
       "    [0.6015256274234219, 0.39847437704692656],\n",
       "    [0.014137839665218317, 0.9858621603347815],\n",
       "    [0.994724316304631, 0.005275678914579811],\n",
       "    [0.9983082636228662, 0.0016917370348802107],\n",
       "    [0.001371926947886285, 0.9986280730521137],\n",
       "    [0.1728073273250729, 0.8271926726749272],\n",
       "    [0.96767082723049, 0.03232917168296689],\n",
       "    [0.004630250633688524, 0.9953697493663115],\n",
       "    [0.9994006173656241, 0.0005993801673412771],\n",
       "    [5.619026555218435e-05, 0.999943809734448],\n",
       "    [0.00011832655507933257, 0.9998816734449207],\n",
       "    [0.0010482006921703488, 0.9989517993078295],\n",
       "    [0.006083701836390213, 0.9939162981636097],\n",
       "    [0.015755441956435242, 0.9842445580435647],\n",
       "    [0.0035011558811238186, 0.9964988441188761],\n",
       "    [0.0023592361053992555, 0.9976407638946008],\n",
       "    [0.0016705205668722828, 0.9983294794331278],\n",
       "    [8.059588819599635e-05, 0.9999194041118039],\n",
       "    [0.22366748630800687, 0.7763325136919934],\n",
       "    [0.001976320939585307, 0.9980236790604148],\n",
       "    [0.000509489489058079, 0.999490510510942],\n",
       "    [0.08956265129285938, 0.9104373487071407],\n",
       "    [0.9982169665503363, 0.0017830317383583315],\n",
       "    [0.010420092866432525, 0.9895799071335675],\n",
       "    [0.004628210283646499, 0.9953717897163533],\n",
       "    [0.005229391994669245, 0.9947706080053308],\n",
       "    [0.9997675719770082, 0.00023242912311655602],\n",
       "    [0.0024645409466982735, 0.9975354590533017],\n",
       "    [0.9994910900676772, 0.000508912157795711],\n",
       "    [0.010393066489989222, 0.9896069335100108],\n",
       "    [0.0016395494252694253, 0.9983604505747306],\n",
       "    [0.9997009399973419, 0.00029906154516101967],\n",
       "    [0.0016713894837613974, 0.9983286105162386],\n",
       "    [0.9978358131195784, 0.0021641884801620924],\n",
       "    [0.09807972143295587, 0.9019202785670442],\n",
       "    [0.6027894104561227, 0.397210589047172],\n",
       "    [0.2075808980121068, 0.7924191029813039],\n",
       "    [0.010587409508495441, 0.9894125904915045],\n",
       "    [0.0007097344632071968, 0.9992902655367928],\n",
       "    [0.0016104762489322232, 0.9983895237510675],\n",
       "    [0.24982946053832247, 0.7501705404550884],\n",
       "    [0.0025134890577927114, 0.9974865109422074],\n",
       "    [0.0017194261611207836, 0.9982805738388791],\n",
       "    [0.001661023078318834, 0.9983389769216813],\n",
       "    [0.00011215496649035576, 0.9998878450335097],\n",
       "    [0.0006785514418483515, 0.9993214485581515]],\n",
       "   'Best_Threshold': [0.901637755229649,\n",
       "    0.384330998802136,\n",
       "    0.5155062297763521,\n",
       "    0.7586576842750771,\n",
       "    0.38433245166349533,\n",
       "    0.5474883671871175,\n",
       "    0.7586576842750771,\n",
       "    0.6156787604716543,\n",
       "    0.5543422900410034,\n",
       "    0.7586576842750771,\n",
       "    0.6961493291169474,\n",
       "    0.67029114071128,\n",
       "    0.7040441568843022,\n",
       "    0.7469818264739659,\n",
       "    0.6156776133205051,\n",
       "    0.8470242278388741,\n",
       "    0.7040441568843022,\n",
       "    0.5543422900410034,\n",
       "    0.6156776133205051,\n",
       "    0.7377971730573245,\n",
       "    0.6079997455476859,\n",
       "    0.8470242278388741,\n",
       "    0.3843323638862662,\n",
       "    0.5147356489025322,\n",
       "    0.6156776133205051,\n",
       "    0.6156775611714203,\n",
       "    0.6116516584745381,\n",
       "    0.8470242278388741,\n",
       "    0.24135092784756415,\n",
       "    0.24135092784756415]}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allResult[0][\"Evaluation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'ID': 'Flow_0_2024-01-28 11:16:18_train', 'Mo...</td>\n",
       "      <td>{'ID': 'Flow_1_2024-01-28 11:16:18_vali', 'Mod...</td>\n",
       "      <td>{'ID': 'Flow_2_2024-01-28 11:16:18_test', 'Mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'f1_1': 0.9976019184652278, 'f1_0': 0.9962264...</td>\n",
       "      <td>{'f1_1': 1.0, 'f1_0': 1.0, 'f1_macro': 1.0, 'f...</td>\n",
       "      <td>{'f1_1': 0.9936305732484078, 'f1_0': 0.9859154...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  {'ID': 'Flow_0_2024-01-28 11:16:18_train', 'Mo...   \n",
       "1  {'f1_1': 0.9976019184652278, 'f1_0': 0.9962264...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  {'ID': 'Flow_1_2024-01-28 11:16:18_vali', 'Mod...   \n",
       "1  {'f1_1': 1.0, 'f1_0': 1.0, 'f1_macro': 1.0, 'f...   \n",
       "\n",
       "                                                   2  \n",
       "0  {'ID': 'Flow_2_2024-01-28 11:16:18_test', 'Mod...  \n",
       "1  {'f1_1': 0.9936305732484078, 'f1_0': 0.9859154...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(result[\"Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"PermutationImportance\"][\"originalData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"PermutationImportance\"][\"trainData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作範例 - Iris Datasets（Multi-class Classification）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = load_iris(as_frame = True)[\"data\"]\n",
    "rawData = pd.concat([rawData, load_iris(as_frame = True)[\"target\"]], axis = 1)\n",
    "rawData = rawData.rename(\n",
    "    columns = {\n",
    "        \"sepal length (cm)\": \"sepal_length_(cm)\",\n",
    "        \"sepal width (cm)\": \"sepal_width_(cm)\",\n",
    "        \"petal length (cm)\": \"petal_length_(cm)\",\n",
    "        \"petal width (cm)\": \"'petal_width_(cm)\"\n",
    "    }\n",
    ")\n",
    "trainData, testData = train_test_split(rawData, test_size = 0.2, shuffle = True) \n",
    "trainData, valiData = train_test_split(trainData, test_size = 0.25, shuffle = True) \n",
    "trainData, valiData, testData = trainData.reset_index(drop = True), valiData.reset_index(drop = True), testData.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineer and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoML_Flow.Model_Training_and_Evaluation_Flow import modelTrainingFlow \n",
    "for oneFE in featureEngineerFlow:\n",
    "    totalResult = modelTrainingFlow(\n",
    "        trainData = trainData,\n",
    "        valiData = valiData,\n",
    "        testData = testData,\n",
    "        inputFeatures = trainData.drop(columns = [\"target\"]).columns.tolist(), \n",
    "        target = \"target\", \n",
    "        targetType = \"classification\",\n",
    "        ml_methods = oneFE,\n",
    "        HTMetric = \"cross_entropy\",\n",
    "        thresholdMetric = \"f1_1\", \n",
    "        featureSelection = oneFE[\"FeatureSelection\"],\n",
    "        hyperparameter_tuning_method = \"TPESampler\", \n",
    "        hyperparameter_tuning_epochs = 1\n",
    "    )\n",
    "    result = totalResult.fit(permutationImportanceMethod = [\"trainData\", \"originalData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"PermutationImportance\"][\"originalData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"PermutationImportance\"][\"trainData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作範例 - Diabete Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = load_diabetes(as_frame = True)[\"data\"]\n",
    "rawData = pd.concat([rawData, load_diabetes(as_frame = True)[\"target\"]], axis = 1)\n",
    "trainData, testData = train_test_split(rawData, test_size = 0.2, shuffle = True) \n",
    "trainData, valiData = train_test_split(trainData, test_size = 0.25, shuffle = True) \n",
    "trainData, valiData, testData = trainData.reset_index(drop = True), valiData.reset_index(drop = True), testData.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineer and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from AutoML_Flow.Model_Training_and_Evaluation_Flow import modelTrainingFlow \n",
    "for oneFE in featureEngineerFlow:\n",
    "    modelTrainingFlow = modelTrainingFlow(\n",
    "        trainData = trainData,\n",
    "        valiData = valiData,\n",
    "        testData = testData,\n",
    "        inputFeatures = trainData.drop(columns = [\"target\"]).columns.tolist(), \n",
    "        target = \"target\", \n",
    "        ml_methods = oneFE,\n",
    "        targetType = \"regression\",\n",
    "        HTMetric = \"RMSE\", \n",
    "        hyperparameter_tuning_method = \"TPESampler\", \n",
    "        hyperparameter_tuning_epochs = 1, \n",
    "        featureSelection = oneFE[\"FeatureSelection\"],\n",
    "        importanceMethod = [\"None\"],\n",
    "        modelNameList = [\n",
    "            [\"LightGBM\", \"CatBoost\"]\n",
    "        ]\n",
    "    )\n",
    "    totalResult = modelTrainingFlow.fit()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(totalResult[\"Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(totalResult[\"Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不平衡資料處理範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.datasets import fetch_dataset\n",
    "dataset = fetch_dataset()[\"thyroid_sick\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "af4a1e6a86c740b63a37040b3f0131c5c5c454fa1507d305e6c23d6bab4bfa1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
