{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes, load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from AutoML_Flow.MLEnv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作範例 - Breast Cancer（Binary Classification）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = load_breast_cancer(as_frame = True)[\"data\"]\n",
    "rawData = pd.concat([rawData, load_breast_cancer(as_frame = True)[\"target\"]], axis = 1)\n",
    "rawData = rawData.rename(\n",
    "    columns = {\n",
    "        i: i.replace(\" \", \"_\") for i in rawData.columns\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwang-jian-an\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wang-jian-an/project-and-jobs/CustomizedAutoML/wandb/run-20240125_163155-dzucnbsz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wang-jian-an/test_wandb_20240125/runs/dzucnbsz' target=\"_blank\">None-None-None-None_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy</a></strong> to <a href='https://wandb.ai/wang-jian-an/test_wandb_20240125' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240125' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240125</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wang-jian-an/test_wandb_20240125/runs/dzucnbsz' target=\"_blank\">https://wandb.ai/wang-jian-an/test_wandb_20240125/runs/dzucnbsz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy Training\n",
      "最佳 Threshold 0.24135092784756415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:32:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.7586576842750771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:32:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.5784824528208832\n",
      "最佳 Threshold 0.1529843842837671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:33:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.6156786781347322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:33:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.5767627908015094\n",
      "最佳 Threshold 0.1529843842837671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:34:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.38433223281571915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:34:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.586417667718358\n",
      "最佳 Threshold 0.24135092784756415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:35:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.2413512936282254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:35:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.4289460693861765\n",
      "最佳 Threshold 0.615679153483821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:36:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.24135224523264287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:36:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.6156771910435068\n",
      "最佳 Threshold 0.3433616680581252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:37:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.7586576842750771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang-jian-an/venv-python310/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:37:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Threshold 0.6057001297144573\n",
      "最佳 Threshold 0.6156788764222223\n"
     ]
    }
   ],
   "source": [
    "from AutoML_Flow.Model_Training_and_Evaluation_Flow import modelTrainingFlow\n",
    "allResult = list()\n",
    "trainData, testData = train_test_split(rawData, test_size = 0.2, shuffle = True) \n",
    "trainData, valiData = train_test_split(trainData, test_size = 0.25, shuffle = True) \n",
    "for oneFE in featureEngineerFlow[:1]:\n",
    "    totalResult = modelTrainingFlow(\n",
    "        trainData = trainData,\n",
    "        valiData = valiData,\n",
    "        testData = testData,\n",
    "        inputFeatures = trainData.drop(columns = [\"target\"]).columns.tolist(), \n",
    "        target = \"target\", \n",
    "        targetType = \"classification\",\n",
    "        ml_methods = oneFE,\n",
    "        hyperparameter_tuning_method = \"default\", \n",
    "        hyperparameter_tuning_epochs = 1, \n",
    "        HTMetric = \"cross_entropy\", \n",
    "        thresholdMetric = \"f1_1\", \n",
    "        featureSelection = oneFE[\"FeatureSelection\"],\n",
    "        modelNameList = [\n",
    "            # [\"Random Forest with Entropy\"],\n",
    "            [\"LightGBM\", \"XGBoost\", \"Random Forest with Entropy\"] * 10, \n",
    "        ], \n",
    "        fitBestModel = False,\n",
    "        metaLearner = \"XGBoost\", \n",
    "        modelFilePath = \"./\", \n",
    "        importanceMethod = [\"None\"]\n",
    "    )\n",
    "    result = totalResult.fit()\n",
    "    allResult.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Evaluation': [{'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "   'Features': ['mean_radius',\n",
       "    'mean_texture',\n",
       "    'mean_perimeter',\n",
       "    'mean_area',\n",
       "    'mean_smoothness',\n",
       "    'mean_compactness',\n",
       "    'mean_concavity',\n",
       "    'mean_concave_points',\n",
       "    'mean_symmetry',\n",
       "    'mean_fractal_dimension',\n",
       "    'radius_error',\n",
       "    'texture_error',\n",
       "    'perimeter_error',\n",
       "    'area_error',\n",
       "    'smoothness_error',\n",
       "    'compactness_error',\n",
       "    'concavity_error',\n",
       "    'concave_points_error',\n",
       "    'symmetry_error',\n",
       "    'fractal_dimension_error',\n",
       "    'worst_radius',\n",
       "    'worst_texture',\n",
       "    'worst_perimeter',\n",
       "    'worst_area',\n",
       "    'worst_smoothness',\n",
       "    'worst_compactness',\n",
       "    'worst_concavity',\n",
       "    'worst_concave_points',\n",
       "    'worst_symmetry',\n",
       "    'worst_fractal_dimension'],\n",
       "   'Set': 'train',\n",
       "   'Number_of_Data': {1: 208, 0: 133},\n",
       "   'f1_1': 0.9928400954653938,\n",
       "   'f1_0': 0.988593155893536,\n",
       "   'f1_macro': 0.9907166256794648,\n",
       "   'f1_micro': 0.9912023460410557,\n",
       "   'prc_auc_1': 0.9998620822760176,\n",
       "   'prc_auc_0': 0.2268892789884035,\n",
       "   'precision_1': 0.985781990521327,\n",
       "   'precision_0': 1.0,\n",
       "   'macro_precision': 0.9928909952606635,\n",
       "   'micro_precision': 0.9912023460410557,\n",
       "   'recall_1': 1.0,\n",
       "   'recall_0': 0.9774436090225563,\n",
       "   'macro_recall': 0.9887218045112782,\n",
       "   'micro_recall': 0.9912023460410557,\n",
       "   'accuracy': 0.9912023460410557,\n",
       "   'roc_auc': 0.9997831116252169,\n",
       "   'cross_entropy': 0.027259106328358266,\n",
       "   'fpr': [0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.007518796992481203,\n",
       "    0.007518796992481203,\n",
       "    0.015037593984962405,\n",
       "    0.015037593984962405,\n",
       "    0.022556390977443608,\n",
       "    0.022556390977443608,\n",
       "    1.0],\n",
       "   'tpr': [0.0,\n",
       "    0.004807692307692308,\n",
       "    0.9855769230769231,\n",
       "    0.9855769230769231,\n",
       "    0.9903846153846154,\n",
       "    0.9903846153846154,\n",
       "    0.9951923076923077,\n",
       "    0.9951923076923077,\n",
       "    1.0,\n",
       "    1.0],\n",
       "   'True_value': [1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_value': [1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_prob_value': [0.99950809699604,\n",
       "    0.0002532106571830315,\n",
       "    0.971378707437667,\n",
       "    0.999902375970393,\n",
       "    0.9956112885446121,\n",
       "    0.9984159001377017,\n",
       "    0.9998861107656704,\n",
       "    0.9994664819550305,\n",
       "    0.9985245440073643,\n",
       "    0.01232689922506673,\n",
       "    0.9965010953570281,\n",
       "    0.9425134100018003,\n",
       "    0.9999485504751026,\n",
       "    0.00013328858038991423,\n",
       "    0.8871019288788976,\n",
       "    0.9976597303464073,\n",
       "    0.9976911050640374,\n",
       "    0.9993674263682591,\n",
       "    0.024618667097331667,\n",
       "    0.9701635803889344,\n",
       "    0.9979467826079359,\n",
       "    0.9992946098927319,\n",
       "    0.9986952233042535,\n",
       "    0.9992392286250757,\n",
       "    0.00010615584855022338,\n",
       "    0.9719763247298803,\n",
       "    0.9998963513109411,\n",
       "    0.9998486881031277,\n",
       "    0.9970940694450545,\n",
       "    0.0003292074469134156,\n",
       "    0.9998576042705822,\n",
       "    0.13092861271016207,\n",
       "    0.0008146857624653211,\n",
       "    0.884291688316469,\n",
       "    0.9998016908846875,\n",
       "    0.03209698765332266,\n",
       "    0.8871541813475884,\n",
       "    0.0002120819790019106,\n",
       "    0.9994485089590951,\n",
       "    0.9992424827930325,\n",
       "    0.9809603537802913,\n",
       "    0.04619744765638556,\n",
       "    0.9991612161346607,\n",
       "    0.9995675507232673,\n",
       "    0.0001772452730437818,\n",
       "    0.9853372169037055,\n",
       "    0.9963064965919558,\n",
       "    0.9997801673471859,\n",
       "    0.950170005177037,\n",
       "    0.0003033666145201091,\n",
       "    0.9996179237963465,\n",
       "    0.9998191150270682,\n",
       "    0.0031950521168341707,\n",
       "    0.9849210335214552,\n",
       "    0.0008572073169222714,\n",
       "    0.9026683297333161,\n",
       "    0.9345734917743457,\n",
       "    0.9980340859392032,\n",
       "    0.9899525902938662,\n",
       "    0.002718064381460843,\n",
       "    0.0001758631761122399,\n",
       "    0.9998721628455672,\n",
       "    0.9960907692509701,\n",
       "    0.002565572967480957,\n",
       "    9.937461906887316e-05,\n",
       "    0.0012050682428849943,\n",
       "    0.9990156920186467,\n",
       "    0.9999444238678715,\n",
       "    0.9906663207026022,\n",
       "    0.9994329038218462,\n",
       "    0.9633817584576587,\n",
       "    0.9998857501184517,\n",
       "    0.0005561299036387759,\n",
       "    0.9990147298060409,\n",
       "    0.9982317680846428,\n",
       "    0.9989271645150642,\n",
       "    0.9997925906271503,\n",
       "    0.9994775788570878,\n",
       "    0.052328630798056816,\n",
       "    0.9991707562753026,\n",
       "    0.0011579394129560198,\n",
       "    0.9998859802153793,\n",
       "    0.990950511795387,\n",
       "    0.9995716563464091,\n",
       "    0.05186697853540792,\n",
       "    0.0330586442991524,\n",
       "    0.9946755431070283,\n",
       "    4.5650679063721525e-05,\n",
       "    0.001131681916377682,\n",
       "    0.00013445143876521782,\n",
       "    0.9999137601831044,\n",
       "    0.9964383074402987,\n",
       "    0.9985451963624938,\n",
       "    0.0014770746114670574,\n",
       "    0.0011340832086109414,\n",
       "    0.9998492740149617,\n",
       "    0.999792570524889,\n",
       "    0.015650380231794873,\n",
       "    0.007853772766722094,\n",
       "    0.9998773287470616,\n",
       "    0.9986591627566107,\n",
       "    0.002141721137224965,\n",
       "    0.06179183559072166,\n",
       "    0.040683296106197774,\n",
       "    0.9995322837567678,\n",
       "    0.002053515244959864,\n",
       "    7.404355938690375e-05,\n",
       "    0.926716837245029,\n",
       "    0.9786525095569673,\n",
       "    0.9824304536661705,\n",
       "    0.03298069478658858,\n",
       "    0.9973190545655832,\n",
       "    0.9998493985173394,\n",
       "    0.9801361371676183,\n",
       "    0.0008085610190659736,\n",
       "    0.9992092210161331,\n",
       "    0.0010869203814328741,\n",
       "    0.9946203276150498,\n",
       "    0.15682166914323845,\n",
       "    0.993230980074771,\n",
       "    0.9988425818840431,\n",
       "    0.9999600174436359,\n",
       "    0.9999268238189533,\n",
       "    0.012114991831486671,\n",
       "    7.791080282446352e-05,\n",
       "    0.0009594158813747589,\n",
       "    0.9691593531939217,\n",
       "    0.00045658624514121596,\n",
       "    0.00012029959758138618,\n",
       "    0.9017543069903698,\n",
       "    0.0009325650270983928,\n",
       "    0.004108767291869161,\n",
       "    0.9999706024605622,\n",
       "    0.9964585120013691,\n",
       "    0.9915222262164459,\n",
       "    0.00016920682540722993,\n",
       "    0.00011367524554232742,\n",
       "    0.003985966092154859,\n",
       "    0.9999319924070191,\n",
       "    0.00014683339140724122,\n",
       "    0.9996555123284991,\n",
       "    0.9998569971116775,\n",
       "    0.9982485757998218,\n",
       "    0.0001225186027042939,\n",
       "    0.9985635179964848,\n",
       "    0.9977693439841043,\n",
       "    0.02098807087130084,\n",
       "    0.08629163405091808,\n",
       "    0.9973154397717041,\n",
       "    0.998103080728639,\n",
       "    0.0029051540256001527,\n",
       "    0.9964748924133894,\n",
       "    0.9844166369488772,\n",
       "    0.9946846261998318,\n",
       "    0.9870312492291262,\n",
       "    0.9995039225450452,\n",
       "    0.9881281070659189,\n",
       "    0.9998777089223284,\n",
       "    0.9991024504269265,\n",
       "    0.9966435156970215,\n",
       "    0.00045698225913613885,\n",
       "    0.9997531502466205,\n",
       "    0.9995723261691235,\n",
       "    0.9876694073074205,\n",
       "    0.8809919920922377,\n",
       "    0.008014564122334377,\n",
       "    0.9999677648379603,\n",
       "    0.999539431672998,\n",
       "    0.993569886187362,\n",
       "    0.0028036329446945608,\n",
       "    0.0062835811627819285,\n",
       "    0.0002715119405115965,\n",
       "    0.9936148440729969,\n",
       "    0.008016140073058637,\n",
       "    0.0031996580417141926,\n",
       "    0.0013921012891760659,\n",
       "    0.98616516014809,\n",
       "    0.019347163608484385,\n",
       "    0.021662778604297828,\n",
       "    0.998260879029673,\n",
       "    0.00010497805138616964,\n",
       "    0.9531927199898581,\n",
       "    9.892009574898564e-05,\n",
       "    0.0006498677011103379,\n",
       "    0.9991592101403399,\n",
       "    0.9992148318557736,\n",
       "    0.997413432452072,\n",
       "    0.0001220833667889767,\n",
       "    0.03237808141912216,\n",
       "    0.047478200626112924,\n",
       "    0.8632666703800608,\n",
       "    0.9096795211063868,\n",
       "    0.0017974521242778544,\n",
       "    0.5083992350350942,\n",
       "    0.9963852697751184,\n",
       "    0.0004881913157784242,\n",
       "    0.9993991339636504,\n",
       "    0.00019390715591678057,\n",
       "    0.9999063904793503,\n",
       "    0.001901457715737688,\n",
       "    0.9186065551742535,\n",
       "    0.998891529617514,\n",
       "    0.002693432542260979,\n",
       "    0.9995155972262212,\n",
       "    0.00046884362542667425,\n",
       "    0.0035417287597689405,\n",
       "    0.9939801500816337,\n",
       "    0.009896288200577356,\n",
       "    0.9992114559565883,\n",
       "    0.009410633891403024,\n",
       "    0.0010137202122566151,\n",
       "    0.00019102609010926923,\n",
       "    9.219504170374858e-05,\n",
       "    0.999891498818113,\n",
       "    0.004580932763058546,\n",
       "    0.0011152422235497783,\n",
       "    0.9997686632871408,\n",
       "    0.0001625495332355312,\n",
       "    0.9009994889840166,\n",
       "    9.747037963125762e-05,\n",
       "    0.0177338464982013,\n",
       "    0.0010583397962969795,\n",
       "    0.9809169554696006,\n",
       "    0.006872394317421665,\n",
       "    0.999969749605843,\n",
       "    0.9915733910193842,\n",
       "    0.9476036155890317,\n",
       "    0.99915900508808,\n",
       "    0.999694082939895,\n",
       "    0.9999440277675612,\n",
       "    0.9971696792088609,\n",
       "    0.0003845553050487854,\n",
       "    0.969074182640059,\n",
       "    0.07366323964566884,\n",
       "    0.043900452093828986,\n",
       "    0.9994998149257565,\n",
       "    0.9765966312742406,\n",
       "    0.9974124039717392,\n",
       "    0.99988602220594,\n",
       "    0.9998369010079075,\n",
       "    0.07202094697366258,\n",
       "    0.9991649716348562,\n",
       "    0.007366826845368199,\n",
       "    0.003289107147037138,\n",
       "    0.00012102083373591497,\n",
       "    0.001413114075503388,\n",
       "    0.9995333120382424,\n",
       "    0.01821466401951232,\n",
       "    0.9991190380281959,\n",
       "    0.0007982754308335403,\n",
       "    0.04853120616958395,\n",
       "    0.0678875258891059,\n",
       "    0.9910634207067389,\n",
       "    0.00023625664624202125,\n",
       "    0.17543620536416496,\n",
       "    0.000574857635916626,\n",
       "    0.9985848459004055,\n",
       "    0.9997208686859973,\n",
       "    0.00035556860658808896,\n",
       "    0.9984765080478761,\n",
       "    0.07546787758117052,\n",
       "    0.00241027527137984,\n",
       "    0.7155787949762913,\n",
       "    0.0023760461524968174,\n",
       "    0.9999139880719571,\n",
       "    0.9875819105097902,\n",
       "    0.9995050954039209,\n",
       "    0.9984119591641691,\n",
       "    0.552381909466323,\n",
       "    0.9988417350312921,\n",
       "    0.9746054656693514,\n",
       "    0.9992238011548379,\n",
       "    0.9998780300781844,\n",
       "    0.9753605581434709,\n",
       "    0.9859916050628148,\n",
       "    0.9923101604266242,\n",
       "    0.9867625779729582,\n",
       "    0.989027235280502,\n",
       "    0.0038952922440056077,\n",
       "    0.987506462061539,\n",
       "    0.0008117003101019989,\n",
       "    0.9995219328613987,\n",
       "    0.006850384531947693,\n",
       "    0.9974939055170917,\n",
       "    0.9974724120158889,\n",
       "    0.9739932957958838,\n",
       "    0.004189163747493807,\n",
       "    0.9828673755698122,\n",
       "    0.9925118894997568,\n",
       "    0.03348745850120893,\n",
       "    0.9997432838676231,\n",
       "    0.9953583020429213,\n",
       "    0.9944111666631448,\n",
       "    0.997538604709144,\n",
       "    0.0004925793980246167,\n",
       "    0.0013243249130498172,\n",
       "    0.9992393071695829,\n",
       "    0.9972430240085514,\n",
       "    0.9986366305340524,\n",
       "    0.011364227985129611,\n",
       "    0.003177733230676312,\n",
       "    0.9985050046512457,\n",
       "    0.9862178255046652,\n",
       "    0.5267742139289092,\n",
       "    0.00011946056073259279,\n",
       "    0.9975492348658556,\n",
       "    0.025082754900196277,\n",
       "    0.9998719392050834,\n",
       "    0.015224714223841827,\n",
       "    0.9942763026422395,\n",
       "    0.00024181143492443965,\n",
       "    0.9890184348854287,\n",
       "    0.026594479573577183,\n",
       "    0.9978193181391831,\n",
       "    0.0009069038000499946,\n",
       "    0.0005438162468716177,\n",
       "    0.9980539958257353,\n",
       "    0.9990842744913958,\n",
       "    0.9745960472443251,\n",
       "    0.9949640020313592,\n",
       "    0.9999025147614357,\n",
       "    0.9989997079078476,\n",
       "    0.9998930642638405,\n",
       "    0.9998913884421529,\n",
       "    0.9998849255124501,\n",
       "    0.8877785909237209,\n",
       "    0.0001251042943334296,\n",
       "    0.9908122416609807,\n",
       "    0.003831234260174549,\n",
       "    0.9859753381774372,\n",
       "    0.9879283355520291,\n",
       "    0.9756746371254453,\n",
       "    0.9983821152969473,\n",
       "    0.6326110044386098,\n",
       "    0.00958418565111496,\n",
       "    0.9998918601639077,\n",
       "    0.18792122970235497,\n",
       "    0.9985605970133645,\n",
       "    0.9998826192940223,\n",
       "    0.9999218122967084,\n",
       "    0.6869193247477443],\n",
       "   'Best_Threshold': [0.6156776133205051,\n",
       "    0.24135092784756415,\n",
       "    0.2336292791682194,\n",
       "    0.32971747141136115,\n",
       "    0.1529843842837671,\n",
       "    0.3843307448687497,\n",
       "    0.24135092784756415,\n",
       "    0.24135092784756415,\n",
       "    0.49532261142066425,\n",
       "    0.567718469985449,\n",
       "    0.24135092784756415,\n",
       "    0.4906503165149528,\n",
       "    0.4909526285053476,\n",
       "    0.24135092784756415,\n",
       "    0.6013408427366176,\n",
       "    0.6156791506186637,\n",
       "    0.48432616284362373,\n",
       "    0.47158240417217606,\n",
       "    0.32971747141136115,\n",
       "    0.4966565364387161,\n",
       "    0.46100468666744854,\n",
       "    0.24135092784756415,\n",
       "    0.3843316205800557,\n",
       "    0.5844129887106144,\n",
       "    0.5516462836175299,\n",
       "    0.6156776133205051,\n",
       "    0.6156770281473449,\n",
       "    0.5651568140419021,\n",
       "    0.38433235668889715,\n",
       "    0.4730261373911418]},\n",
       "  {'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "   'Features': ['mean_radius',\n",
       "    'mean_texture',\n",
       "    'mean_perimeter',\n",
       "    'mean_area',\n",
       "    'mean_smoothness',\n",
       "    'mean_compactness',\n",
       "    'mean_concavity',\n",
       "    'mean_concave_points',\n",
       "    'mean_symmetry',\n",
       "    'mean_fractal_dimension',\n",
       "    'radius_error',\n",
       "    'texture_error',\n",
       "    'perimeter_error',\n",
       "    'area_error',\n",
       "    'smoothness_error',\n",
       "    'compactness_error',\n",
       "    'concavity_error',\n",
       "    'concave_points_error',\n",
       "    'symmetry_error',\n",
       "    'fractal_dimension_error',\n",
       "    'worst_radius',\n",
       "    'worst_texture',\n",
       "    'worst_perimeter',\n",
       "    'worst_area',\n",
       "    'worst_smoothness',\n",
       "    'worst_compactness',\n",
       "    'worst_concavity',\n",
       "    'worst_concave_points',\n",
       "    'worst_symmetry',\n",
       "    'worst_fractal_dimension'],\n",
       "   'Set': 'vali',\n",
       "   'Number_of_Data': {1: 70, 0: 44},\n",
       "   'f1_1': 1.0,\n",
       "   'f1_0': 1.0,\n",
       "   'f1_macro': 1.0,\n",
       "   'f1_micro': 1.0,\n",
       "   'prc_auc_1': 0.9999999999999999,\n",
       "   'prc_auc_0': 0.22409168083062822,\n",
       "   'precision_1': 1.0,\n",
       "   'precision_0': 1.0,\n",
       "   'macro_precision': 1.0,\n",
       "   'micro_precision': 1.0,\n",
       "   'recall_1': 1.0,\n",
       "   'recall_0': 1.0,\n",
       "   'macro_recall': 1.0,\n",
       "   'micro_recall': 1.0,\n",
       "   'accuracy': 1.0,\n",
       "   'roc_auc': 1.0,\n",
       "   'cross_entropy': 0.013380150817586648,\n",
       "   'fpr': [0.0, 0.0, 0.0, 1.0],\n",
       "   'tpr': [0.0, 0.014285714285714285, 1.0, 1.0],\n",
       "   'True_value': [1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_value': [1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_prob_value': [0.9453506464574714,\n",
       "    0.0004553214057071509,\n",
       "    0.1193875789120416,\n",
       "    0.9899053024140584,\n",
       "    0.9972450269971873,\n",
       "    0.9998208503797462,\n",
       "    0.043528557506378414,\n",
       "    0.0002297897030311269,\n",
       "    0.0004893812311508544,\n",
       "    0.011837723277556323,\n",
       "    0.9998847351607196,\n",
       "    0.9781971196188712,\n",
       "    0.9982037218392255,\n",
       "    0.9984850806623012,\n",
       "    0.9998915152963911,\n",
       "    0.9999158772336327,\n",
       "    0.00024397848002844492,\n",
       "    0.00010997334832719567,\n",
       "    0.9983357935991157,\n",
       "    0.00024183623387602404,\n",
       "    0.15423397355730714,\n",
       "    0.9998033103671669,\n",
       "    0.014315633529964898,\n",
       "    0.981952736508475,\n",
       "    0.00013538380994051815,\n",
       "    0.9999026080500779,\n",
       "    0.9990316988171047,\n",
       "    0.017176672843536262,\n",
       "    0.999511557948699,\n",
       "    0.9990698411437264,\n",
       "    0.9996585452295078,\n",
       "    0.9999341942619909,\n",
       "    0.9997977571318775,\n",
       "    0.00014232630744147936,\n",
       "    0.01113737918771715,\n",
       "    0.9999397569996715,\n",
       "    0.9966669126490844,\n",
       "    0.00019938649091401134,\n",
       "    0.9994561018705972,\n",
       "    0.008703439897516445,\n",
       "    0.00013749006629608978,\n",
       "    0.005246802016457175,\n",
       "    7.266173052889907e-05,\n",
       "    0.9487185051506377,\n",
       "    0.000411785657031715,\n",
       "    0.937968043274067,\n",
       "    0.9985263173383443,\n",
       "    0.9999257199592682,\n",
       "    0.9630584353397196,\n",
       "    0.9884560792072181,\n",
       "    0.00015826935595862258,\n",
       "    0.0001263898345032581,\n",
       "    0.010539370382971818,\n",
       "    0.9999355939681985,\n",
       "    0.9842323798915625,\n",
       "    0.9998510812570021,\n",
       "    0.9917466602224656,\n",
       "    0.9999302722697707,\n",
       "    0.046604598660069566,\n",
       "    0.999852725068949,\n",
       "    0.0015977434141760541,\n",
       "    0.9834860878257987,\n",
       "    0.011865375510105585,\n",
       "    0.9997932620449972,\n",
       "    0.0004219093277643047,\n",
       "    0.001912078640477238,\n",
       "    0.9998794240535861,\n",
       "    0.002030200376593682,\n",
       "    0.994154836693855,\n",
       "    0.9994092697475084,\n",
       "    0.0001451546815675963,\n",
       "    0.9963530373210089,\n",
       "    0.9999475660895756,\n",
       "    0.9563901111691039,\n",
       "    0.9998760587318991,\n",
       "    0.9782881551432404,\n",
       "    0.0004709064664042419,\n",
       "    0.9998830451466649,\n",
       "    0.00017312807911928164,\n",
       "    0.06727440911104685,\n",
       "    0.9988689671448322,\n",
       "    0.9859928811481328,\n",
       "    0.9999095551340598,\n",
       "    0.0016233221908155836,\n",
       "    0.9930219235777954,\n",
       "    0.9972701471816904,\n",
       "    0.9979202818281864,\n",
       "    0.9994149893277926,\n",
       "    0.997126751399156,\n",
       "    0.9378545758106649,\n",
       "    0.05894631983957724,\n",
       "    0.9941000718333507,\n",
       "    0.9892417644870722,\n",
       "    0.00012224172913657998,\n",
       "    0.006049319427043736,\n",
       "    0.9155287592345547,\n",
       "    4.501828754636588e-05,\n",
       "    0.9993032463376565,\n",
       "    0.012257734798100117,\n",
       "    0.020366008489980547,\n",
       "    0.07013666889312903,\n",
       "    0.9949316058147175,\n",
       "    0.9997612188234446,\n",
       "    0.9998046439839968,\n",
       "    0.9998995650027301,\n",
       "    0.9941721658440663,\n",
       "    0.11729900800576676,\n",
       "    0.9717986946879208,\n",
       "    0.9886113546216929,\n",
       "    0.9995393377133205,\n",
       "    0.005038646904553632,\n",
       "    0.9977584568791555,\n",
       "    0.9995546007983483,\n",
       "    0.9997489708649646],\n",
       "   'Best_Threshold': [0.6156776133205051,\n",
       "    0.24135092784756415,\n",
       "    0.2336292791682194,\n",
       "    0.32971747141136115,\n",
       "    0.1529843842837671,\n",
       "    0.3843307448687497,\n",
       "    0.24135092784756415,\n",
       "    0.24135092784756415,\n",
       "    0.49532261142066425,\n",
       "    0.567718469985449,\n",
       "    0.24135092784756415,\n",
       "    0.4906503165149528,\n",
       "    0.4909526285053476,\n",
       "    0.24135092784756415,\n",
       "    0.6013408427366176,\n",
       "    0.6156791506186637,\n",
       "    0.48432616284362373,\n",
       "    0.47158240417217606,\n",
       "    0.32971747141136115,\n",
       "    0.4966565364387161,\n",
       "    0.46100468666744854,\n",
       "    0.24135092784756415,\n",
       "    0.3843316205800557,\n",
       "    0.5844129887106144,\n",
       "    0.5516462836175299,\n",
       "    0.6156776133205051,\n",
       "    0.6156770281473449,\n",
       "    0.5651568140419021,\n",
       "    0.38433235668889715,\n",
       "    0.4730261373911418]},\n",
       "  {'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "   'Features': ['mean_radius',\n",
       "    'mean_texture',\n",
       "    'mean_perimeter',\n",
       "    'mean_area',\n",
       "    'mean_smoothness',\n",
       "    'mean_compactness',\n",
       "    'mean_concavity',\n",
       "    'mean_concave_points',\n",
       "    'mean_symmetry',\n",
       "    'mean_fractal_dimension',\n",
       "    'radius_error',\n",
       "    'texture_error',\n",
       "    'perimeter_error',\n",
       "    'area_error',\n",
       "    'smoothness_error',\n",
       "    'compactness_error',\n",
       "    'concavity_error',\n",
       "    'concave_points_error',\n",
       "    'symmetry_error',\n",
       "    'fractal_dimension_error',\n",
       "    'worst_radius',\n",
       "    'worst_texture',\n",
       "    'worst_perimeter',\n",
       "    'worst_area',\n",
       "    'worst_smoothness',\n",
       "    'worst_compactness',\n",
       "    'worst_concavity',\n",
       "    'worst_concave_points',\n",
       "    'worst_symmetry',\n",
       "    'worst_fractal_dimension'],\n",
       "   'Set': 'test',\n",
       "   'Number_of_Data': {1: 79, 0: 35},\n",
       "   'f1_1': 0.9570552147239264,\n",
       "   'f1_0': 0.8923076923076922,\n",
       "   'f1_macro': 0.9246814535158093,\n",
       "   'f1_micro': 0.9385964912280702,\n",
       "   'prc_auc_1': 0.9927576450936533,\n",
       "   'prc_auc_0': 0.17243272558302342,\n",
       "   'precision_1': 0.9285714285714286,\n",
       "   'precision_0': 0.9666666666666667,\n",
       "   'macro_precision': 0.9476190476190476,\n",
       "   'micro_precision': 0.9385964912280702,\n",
       "   'recall_1': 0.9873417721518988,\n",
       "   'recall_0': 0.8285714285714286,\n",
       "   'macro_recall': 0.9079566003616637,\n",
       "   'micro_recall': 0.9385964912280702,\n",
       "   'accuracy': 0.9385964912280702,\n",
       "   'roc_auc': 0.9851717902350814,\n",
       "   'cross_entropy': 0.1299549303967804,\n",
       "   'fpr': [0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.02857142857142857,\n",
       "    0.02857142857142857,\n",
       "    0.05714285714285714,\n",
       "    0.05714285714285714,\n",
       "    0.08571428571428572,\n",
       "    0.08571428571428572,\n",
       "    0.17142857142857143,\n",
       "    0.17142857142857143,\n",
       "    1.0],\n",
       "   'tpr': [0.0,\n",
       "    0.012658227848101266,\n",
       "    0.6835443037974683,\n",
       "    0.6835443037974683,\n",
       "    0.9113924050632911,\n",
       "    0.9113924050632911,\n",
       "    0.9240506329113924,\n",
       "    0.9240506329113924,\n",
       "    0.9873417721518988,\n",
       "    0.9873417721518988,\n",
       "    1.0,\n",
       "    1.0],\n",
       "   'True_value': [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_value': [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   'Predict_prob_value': [0.9935261794349733,\n",
       "    0.9969119166470392,\n",
       "    0.9970764392421809,\n",
       "    0.996531417401794,\n",
       "    0.00013566821316321966,\n",
       "    0.9895757089569861,\n",
       "    0.999784549915557,\n",
       "    0.0008652475754407298,\n",
       "    0.8705835279900974,\n",
       "    0.9828265687610631,\n",
       "    0.9978982037506147,\n",
       "    0.5695675361076621,\n",
       "    0.9985755118128001,\n",
       "    0.9919325713788155,\n",
       "    0.9962082073089992,\n",
       "    0.9967044029454192,\n",
       "    0.9944262650029717,\n",
       "    0.7987337182266896,\n",
       "    0.9945713740825542,\n",
       "    0.31121279308394434,\n",
       "    0.007277824610930851,\n",
       "    0.9982916701158442,\n",
       "    0.9956727190356219,\n",
       "    0.9819111079560121,\n",
       "    0.7174323468950778,\n",
       "    0.005198720131820495,\n",
       "    0.9864239454955722,\n",
       "    0.9449721965777645,\n",
       "    0.5595925966133312,\n",
       "    0.9844844061517565,\n",
       "    0.29367262082803963,\n",
       "    9.664871660687357e-05,\n",
       "    0.002212428787533484,\n",
       "    0.9995886610611566,\n",
       "    0.00025403757199061344,\n",
       "    0.9960773509133081,\n",
       "    0.9999158263291277,\n",
       "    0.9957868797829046,\n",
       "    0.9987860628236139,\n",
       "    0.00047411655067745986,\n",
       "    0.0005661986278172801,\n",
       "    0.9235806995005726,\n",
       "    0.9912252251851814,\n",
       "    0.8096676683169327,\n",
       "    0.9995347136255845,\n",
       "    0.9956498089700135,\n",
       "    0.9999023251002647,\n",
       "    0.834735954784589,\n",
       "    0.6296123519284131,\n",
       "    0.9984836819687521,\n",
       "    0.9858866399067667,\n",
       "    0.9985274984881245,\n",
       "    0.9967849497426983,\n",
       "    0.989647735290381,\n",
       "    0.9999623172147808,\n",
       "    0.9826551099416857,\n",
       "    0.999930171751782,\n",
       "    0.0002164420794067169,\n",
       "    0.9573603342038339,\n",
       "    0.9998921125583897,\n",
       "    0.9992805136921048,\n",
       "    0.00021998125750758444,\n",
       "    0.9999443566307168,\n",
       "    0.03262204504640408,\n",
       "    0.7752071000876307,\n",
       "    7.658733074491253e-05,\n",
       "    0.9999254886589805,\n",
       "    0.005038816722204683,\n",
       "    0.008516477707403585,\n",
       "    0.991522146603193,\n",
       "    0.05618269824725004,\n",
       "    0.9873849100648336,\n",
       "    0.9999252991195432,\n",
       "    0.9999616193421499,\n",
       "    0.6925111854651713,\n",
       "    0.9964828559980242,\n",
       "    0.9991921255924889,\n",
       "    0.9947804460029415,\n",
       "    0.9969481849883548,\n",
       "    0.9992794698842337,\n",
       "    9.581326932211112e-05,\n",
       "    0.021146062864051917,\n",
       "    0.9936531137594281,\n",
       "    0.00022752097402560563,\n",
       "    0.005384346463204516,\n",
       "    0.786198492088866,\n",
       "    0.9998373438668355,\n",
       "    0.9981999986466313,\n",
       "    0.01133869748912588,\n",
       "    0.9963524966770698,\n",
       "    0.9599217992714519,\n",
       "    0.012747450094715134,\n",
       "    0.99988251129582,\n",
       "    0.00017444503316423602,\n",
       "    0.9995308916595497,\n",
       "    0.9995809031339494,\n",
       "    0.9985874824842828,\n",
       "    0.9998582775728392,\n",
       "    0.9962188981480756,\n",
       "    0.7766622717123486,\n",
       "    0.04326878905134039,\n",
       "    0.998249366359605,\n",
       "    0.43181016198004474,\n",
       "    0.9992753959656163,\n",
       "    0.03357035182606197,\n",
       "    0.0005423786999758878,\n",
       "    0.9194151833757525,\n",
       "    0.9890222595265059,\n",
       "    0.002099845108758709,\n",
       "    0.02966660152062737,\n",
       "    0.9619946284512454,\n",
       "    0.9977890217849662,\n",
       "    0.9126873301946253,\n",
       "    0.8917273400866946],\n",
       "   'Best_Threshold': [0.6156776133205051,\n",
       "    0.24135092784756415,\n",
       "    0.2336292791682194,\n",
       "    0.32971747141136115,\n",
       "    0.1529843842837671,\n",
       "    0.3843307448687497,\n",
       "    0.24135092784756415,\n",
       "    0.24135092784756415,\n",
       "    0.49532261142066425,\n",
       "    0.567718469985449,\n",
       "    0.24135092784756415,\n",
       "    0.4906503165149528,\n",
       "    0.4909526285053476,\n",
       "    0.24135092784756415,\n",
       "    0.6013408427366176,\n",
       "    0.6156791506186637,\n",
       "    0.48432616284362373,\n",
       "    0.47158240417217606,\n",
       "    0.32971747141136115,\n",
       "    0.4966565364387161,\n",
       "    0.46100468666744854,\n",
       "    0.24135092784756415,\n",
       "    0.3843316205800557,\n",
       "    0.5844129887106144,\n",
       "    0.5516462836175299,\n",
       "    0.6156776133205051,\n",
       "    0.6156770281473449,\n",
       "    0.5651568140419021,\n",
       "    0.38433235668889715,\n",
       "    0.4730261373911418]}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "  'Features': ['mean_radius',\n",
       "   'mean_texture',\n",
       "   'mean_perimeter',\n",
       "   'mean_area',\n",
       "   'mean_smoothness',\n",
       "   'mean_compactness',\n",
       "   'mean_concavity',\n",
       "   'mean_concave_points',\n",
       "   'mean_symmetry',\n",
       "   'mean_fractal_dimension',\n",
       "   'radius_error',\n",
       "   'texture_error',\n",
       "   'perimeter_error',\n",
       "   'area_error',\n",
       "   'smoothness_error',\n",
       "   'compactness_error',\n",
       "   'concavity_error',\n",
       "   'concave_points_error',\n",
       "   'symmetry_error',\n",
       "   'fractal_dimension_error',\n",
       "   'worst_radius',\n",
       "   'worst_texture',\n",
       "   'worst_perimeter',\n",
       "   'worst_area',\n",
       "   'worst_smoothness',\n",
       "   'worst_compactness',\n",
       "   'worst_concavity',\n",
       "   'worst_concave_points',\n",
       "   'worst_symmetry',\n",
       "   'worst_fractal_dimension'],\n",
       "  'Set': 'train',\n",
       "  'Number_of_Data': {1: 208, 0: 133},\n",
       "  'f1_1': 0.9928400954653938,\n",
       "  'f1_0': 0.988593155893536,\n",
       "  'f1_macro': 0.9907166256794648,\n",
       "  'f1_micro': 0.9912023460410557,\n",
       "  'prc_auc_1': 0.9998620822760176,\n",
       "  'prc_auc_0': 0.2268892789884035,\n",
       "  'precision_1': 0.985781990521327,\n",
       "  'precision_0': 1.0,\n",
       "  'macro_precision': 0.9928909952606635,\n",
       "  'micro_precision': 0.9912023460410557,\n",
       "  'recall_1': 1.0,\n",
       "  'recall_0': 0.9774436090225563,\n",
       "  'macro_recall': 0.9887218045112782,\n",
       "  'micro_recall': 0.9912023460410557,\n",
       "  'accuracy': 0.9912023460410557,\n",
       "  'roc_auc': 0.9997831116252169,\n",
       "  'cross_entropy': 0.027259106328358266,\n",
       "  'fpr': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.007518796992481203,\n",
       "   0.007518796992481203,\n",
       "   0.015037593984962405,\n",
       "   0.015037593984962405,\n",
       "   0.022556390977443608,\n",
       "   0.022556390977443608,\n",
       "   1.0],\n",
       "  'tpr': [0.0,\n",
       "   0.004807692307692308,\n",
       "   0.9855769230769231,\n",
       "   0.9855769230769231,\n",
       "   0.9903846153846154,\n",
       "   0.9903846153846154,\n",
       "   0.9951923076923077,\n",
       "   0.9951923076923077,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'True_value': [1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  'Predict_value': [1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  'Predict_prob_value': [0.99950809699604,\n",
       "   0.0002532106571830315,\n",
       "   0.971378707437667,\n",
       "   0.999902375970393,\n",
       "   0.9956112885446121,\n",
       "   0.9984159001377017,\n",
       "   0.9998861107656704,\n",
       "   0.9994664819550305,\n",
       "   0.9985245440073643,\n",
       "   0.01232689922506673,\n",
       "   0.9965010953570281,\n",
       "   0.9425134100018003,\n",
       "   0.9999485504751026,\n",
       "   0.00013328858038991423,\n",
       "   0.8871019288788976,\n",
       "   0.9976597303464073,\n",
       "   0.9976911050640374,\n",
       "   0.9993674263682591,\n",
       "   0.024618667097331667,\n",
       "   0.9701635803889344,\n",
       "   0.9979467826079359,\n",
       "   0.9992946098927319,\n",
       "   0.9986952233042535,\n",
       "   0.9992392286250757,\n",
       "   0.00010615584855022338,\n",
       "   0.9719763247298803,\n",
       "   0.9998963513109411,\n",
       "   0.9998486881031277,\n",
       "   0.9970940694450545,\n",
       "   0.0003292074469134156,\n",
       "   0.9998576042705822,\n",
       "   0.13092861271016207,\n",
       "   0.0008146857624653211,\n",
       "   0.884291688316469,\n",
       "   0.9998016908846875,\n",
       "   0.03209698765332266,\n",
       "   0.8871541813475884,\n",
       "   0.0002120819790019106,\n",
       "   0.9994485089590951,\n",
       "   0.9992424827930325,\n",
       "   0.9809603537802913,\n",
       "   0.04619744765638556,\n",
       "   0.9991612161346607,\n",
       "   0.9995675507232673,\n",
       "   0.0001772452730437818,\n",
       "   0.9853372169037055,\n",
       "   0.9963064965919558,\n",
       "   0.9997801673471859,\n",
       "   0.950170005177037,\n",
       "   0.0003033666145201091,\n",
       "   0.9996179237963465,\n",
       "   0.9998191150270682,\n",
       "   0.0031950521168341707,\n",
       "   0.9849210335214552,\n",
       "   0.0008572073169222714,\n",
       "   0.9026683297333161,\n",
       "   0.9345734917743457,\n",
       "   0.9980340859392032,\n",
       "   0.9899525902938662,\n",
       "   0.002718064381460843,\n",
       "   0.0001758631761122399,\n",
       "   0.9998721628455672,\n",
       "   0.9960907692509701,\n",
       "   0.002565572967480957,\n",
       "   9.937461906887316e-05,\n",
       "   0.0012050682428849943,\n",
       "   0.9990156920186467,\n",
       "   0.9999444238678715,\n",
       "   0.9906663207026022,\n",
       "   0.9994329038218462,\n",
       "   0.9633817584576587,\n",
       "   0.9998857501184517,\n",
       "   0.0005561299036387759,\n",
       "   0.9990147298060409,\n",
       "   0.9982317680846428,\n",
       "   0.9989271645150642,\n",
       "   0.9997925906271503,\n",
       "   0.9994775788570878,\n",
       "   0.052328630798056816,\n",
       "   0.9991707562753026,\n",
       "   0.0011579394129560198,\n",
       "   0.9998859802153793,\n",
       "   0.990950511795387,\n",
       "   0.9995716563464091,\n",
       "   0.05186697853540792,\n",
       "   0.0330586442991524,\n",
       "   0.9946755431070283,\n",
       "   4.5650679063721525e-05,\n",
       "   0.001131681916377682,\n",
       "   0.00013445143876521782,\n",
       "   0.9999137601831044,\n",
       "   0.9964383074402987,\n",
       "   0.9985451963624938,\n",
       "   0.0014770746114670574,\n",
       "   0.0011340832086109414,\n",
       "   0.9998492740149617,\n",
       "   0.999792570524889,\n",
       "   0.015650380231794873,\n",
       "   0.007853772766722094,\n",
       "   0.9998773287470616,\n",
       "   0.9986591627566107,\n",
       "   0.002141721137224965,\n",
       "   0.06179183559072166,\n",
       "   0.040683296106197774,\n",
       "   0.9995322837567678,\n",
       "   0.002053515244959864,\n",
       "   7.404355938690375e-05,\n",
       "   0.926716837245029,\n",
       "   0.9786525095569673,\n",
       "   0.9824304536661705,\n",
       "   0.03298069478658858,\n",
       "   0.9973190545655832,\n",
       "   0.9998493985173394,\n",
       "   0.9801361371676183,\n",
       "   0.0008085610190659736,\n",
       "   0.9992092210161331,\n",
       "   0.0010869203814328741,\n",
       "   0.9946203276150498,\n",
       "   0.15682166914323845,\n",
       "   0.993230980074771,\n",
       "   0.9988425818840431,\n",
       "   0.9999600174436359,\n",
       "   0.9999268238189533,\n",
       "   0.012114991831486671,\n",
       "   7.791080282446352e-05,\n",
       "   0.0009594158813747589,\n",
       "   0.9691593531939217,\n",
       "   0.00045658624514121596,\n",
       "   0.00012029959758138618,\n",
       "   0.9017543069903698,\n",
       "   0.0009325650270983928,\n",
       "   0.004108767291869161,\n",
       "   0.9999706024605622,\n",
       "   0.9964585120013691,\n",
       "   0.9915222262164459,\n",
       "   0.00016920682540722993,\n",
       "   0.00011367524554232742,\n",
       "   0.003985966092154859,\n",
       "   0.9999319924070191,\n",
       "   0.00014683339140724122,\n",
       "   0.9996555123284991,\n",
       "   0.9998569971116775,\n",
       "   0.9982485757998218,\n",
       "   0.0001225186027042939,\n",
       "   0.9985635179964848,\n",
       "   0.9977693439841043,\n",
       "   0.02098807087130084,\n",
       "   0.08629163405091808,\n",
       "   0.9973154397717041,\n",
       "   0.998103080728639,\n",
       "   0.0029051540256001527,\n",
       "   0.9964748924133894,\n",
       "   0.9844166369488772,\n",
       "   0.9946846261998318,\n",
       "   0.9870312492291262,\n",
       "   0.9995039225450452,\n",
       "   0.9881281070659189,\n",
       "   0.9998777089223284,\n",
       "   0.9991024504269265,\n",
       "   0.9966435156970215,\n",
       "   0.00045698225913613885,\n",
       "   0.9997531502466205,\n",
       "   0.9995723261691235,\n",
       "   0.9876694073074205,\n",
       "   0.8809919920922377,\n",
       "   0.008014564122334377,\n",
       "   0.9999677648379603,\n",
       "   0.999539431672998,\n",
       "   0.993569886187362,\n",
       "   0.0028036329446945608,\n",
       "   0.0062835811627819285,\n",
       "   0.0002715119405115965,\n",
       "   0.9936148440729969,\n",
       "   0.008016140073058637,\n",
       "   0.0031996580417141926,\n",
       "   0.0013921012891760659,\n",
       "   0.98616516014809,\n",
       "   0.019347163608484385,\n",
       "   0.021662778604297828,\n",
       "   0.998260879029673,\n",
       "   0.00010497805138616964,\n",
       "   0.9531927199898581,\n",
       "   9.892009574898564e-05,\n",
       "   0.0006498677011103379,\n",
       "   0.9991592101403399,\n",
       "   0.9992148318557736,\n",
       "   0.997413432452072,\n",
       "   0.0001220833667889767,\n",
       "   0.03237808141912216,\n",
       "   0.047478200626112924,\n",
       "   0.8632666703800608,\n",
       "   0.9096795211063868,\n",
       "   0.0017974521242778544,\n",
       "   0.5083992350350942,\n",
       "   0.9963852697751184,\n",
       "   0.0004881913157784242,\n",
       "   0.9993991339636504,\n",
       "   0.00019390715591678057,\n",
       "   0.9999063904793503,\n",
       "   0.001901457715737688,\n",
       "   0.9186065551742535,\n",
       "   0.998891529617514,\n",
       "   0.002693432542260979,\n",
       "   0.9995155972262212,\n",
       "   0.00046884362542667425,\n",
       "   0.0035417287597689405,\n",
       "   0.9939801500816337,\n",
       "   0.009896288200577356,\n",
       "   0.9992114559565883,\n",
       "   0.009410633891403024,\n",
       "   0.0010137202122566151,\n",
       "   0.00019102609010926923,\n",
       "   9.219504170374858e-05,\n",
       "   0.999891498818113,\n",
       "   0.004580932763058546,\n",
       "   0.0011152422235497783,\n",
       "   0.9997686632871408,\n",
       "   0.0001625495332355312,\n",
       "   0.9009994889840166,\n",
       "   9.747037963125762e-05,\n",
       "   0.0177338464982013,\n",
       "   0.0010583397962969795,\n",
       "   0.9809169554696006,\n",
       "   0.006872394317421665,\n",
       "   0.999969749605843,\n",
       "   0.9915733910193842,\n",
       "   0.9476036155890317,\n",
       "   0.99915900508808,\n",
       "   0.999694082939895,\n",
       "   0.9999440277675612,\n",
       "   0.9971696792088609,\n",
       "   0.0003845553050487854,\n",
       "   0.969074182640059,\n",
       "   0.07366323964566884,\n",
       "   0.043900452093828986,\n",
       "   0.9994998149257565,\n",
       "   0.9765966312742406,\n",
       "   0.9974124039717392,\n",
       "   0.99988602220594,\n",
       "   0.9998369010079075,\n",
       "   0.07202094697366258,\n",
       "   0.9991649716348562,\n",
       "   0.007366826845368199,\n",
       "   0.003289107147037138,\n",
       "   0.00012102083373591497,\n",
       "   0.001413114075503388,\n",
       "   0.9995333120382424,\n",
       "   0.01821466401951232,\n",
       "   0.9991190380281959,\n",
       "   0.0007982754308335403,\n",
       "   0.04853120616958395,\n",
       "   0.0678875258891059,\n",
       "   0.9910634207067389,\n",
       "   0.00023625664624202125,\n",
       "   0.17543620536416496,\n",
       "   0.000574857635916626,\n",
       "   0.9985848459004055,\n",
       "   0.9997208686859973,\n",
       "   0.00035556860658808896,\n",
       "   0.9984765080478761,\n",
       "   0.07546787758117052,\n",
       "   0.00241027527137984,\n",
       "   0.7155787949762913,\n",
       "   0.0023760461524968174,\n",
       "   0.9999139880719571,\n",
       "   0.9875819105097902,\n",
       "   0.9995050954039209,\n",
       "   0.9984119591641691,\n",
       "   0.552381909466323,\n",
       "   0.9988417350312921,\n",
       "   0.9746054656693514,\n",
       "   0.9992238011548379,\n",
       "   0.9998780300781844,\n",
       "   0.9753605581434709,\n",
       "   0.9859916050628148,\n",
       "   0.9923101604266242,\n",
       "   0.9867625779729582,\n",
       "   0.989027235280502,\n",
       "   0.0038952922440056077,\n",
       "   0.987506462061539,\n",
       "   0.0008117003101019989,\n",
       "   0.9995219328613987,\n",
       "   0.006850384531947693,\n",
       "   0.9974939055170917,\n",
       "   0.9974724120158889,\n",
       "   0.9739932957958838,\n",
       "   0.004189163747493807,\n",
       "   0.9828673755698122,\n",
       "   0.9925118894997568,\n",
       "   0.03348745850120893,\n",
       "   0.9997432838676231,\n",
       "   0.9953583020429213,\n",
       "   0.9944111666631448,\n",
       "   0.997538604709144,\n",
       "   0.0004925793980246167,\n",
       "   0.0013243249130498172,\n",
       "   0.9992393071695829,\n",
       "   0.9972430240085514,\n",
       "   0.9986366305340524,\n",
       "   0.011364227985129611,\n",
       "   0.003177733230676312,\n",
       "   0.9985050046512457,\n",
       "   0.9862178255046652,\n",
       "   0.5267742139289092,\n",
       "   0.00011946056073259279,\n",
       "   0.9975492348658556,\n",
       "   0.025082754900196277,\n",
       "   0.9998719392050834,\n",
       "   0.015224714223841827,\n",
       "   0.9942763026422395,\n",
       "   0.00024181143492443965,\n",
       "   0.9890184348854287,\n",
       "   0.026594479573577183,\n",
       "   0.9978193181391831,\n",
       "   0.0009069038000499946,\n",
       "   0.0005438162468716177,\n",
       "   0.9980539958257353,\n",
       "   0.9990842744913958,\n",
       "   0.9745960472443251,\n",
       "   0.9949640020313592,\n",
       "   0.9999025147614357,\n",
       "   0.9989997079078476,\n",
       "   0.9998930642638405,\n",
       "   0.9998913884421529,\n",
       "   0.9998849255124501,\n",
       "   0.8877785909237209,\n",
       "   0.0001251042943334296,\n",
       "   0.9908122416609807,\n",
       "   0.003831234260174549,\n",
       "   0.9859753381774372,\n",
       "   0.9879283355520291,\n",
       "   0.9756746371254453,\n",
       "   0.9983821152969473,\n",
       "   0.6326110044386098,\n",
       "   0.00958418565111496,\n",
       "   0.9998918601639077,\n",
       "   0.18792122970235497,\n",
       "   0.9985605970133645,\n",
       "   0.9998826192940223,\n",
       "   0.9999218122967084,\n",
       "   0.6869193247477443],\n",
       "  'Best_Threshold': [0.6156776133205051,\n",
       "   0.24135092784756415,\n",
       "   0.2336292791682194,\n",
       "   0.32971747141136115,\n",
       "   0.1529843842837671,\n",
       "   0.3843307448687497,\n",
       "   0.24135092784756415,\n",
       "   0.24135092784756415,\n",
       "   0.49532261142066425,\n",
       "   0.567718469985449,\n",
       "   0.24135092784756415,\n",
       "   0.4906503165149528,\n",
       "   0.4909526285053476,\n",
       "   0.24135092784756415,\n",
       "   0.6013408427366176,\n",
       "   0.6156791506186637,\n",
       "   0.48432616284362373,\n",
       "   0.47158240417217606,\n",
       "   0.32971747141136115,\n",
       "   0.4966565364387161,\n",
       "   0.46100468666744854,\n",
       "   0.24135092784756415,\n",
       "   0.3843316205800557,\n",
       "   0.5844129887106144,\n",
       "   0.5516462836175299,\n",
       "   0.6156776133205051,\n",
       "   0.6156770281473449,\n",
       "   0.5651568140419021,\n",
       "   0.38433235668889715,\n",
       "   0.4730261373911418]},\n",
       " {'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "  'Features': ['mean_radius',\n",
       "   'mean_texture',\n",
       "   'mean_perimeter',\n",
       "   'mean_area',\n",
       "   'mean_smoothness',\n",
       "   'mean_compactness',\n",
       "   'mean_concavity',\n",
       "   'mean_concave_points',\n",
       "   'mean_symmetry',\n",
       "   'mean_fractal_dimension',\n",
       "   'radius_error',\n",
       "   'texture_error',\n",
       "   'perimeter_error',\n",
       "   'area_error',\n",
       "   'smoothness_error',\n",
       "   'compactness_error',\n",
       "   'concavity_error',\n",
       "   'concave_points_error',\n",
       "   'symmetry_error',\n",
       "   'fractal_dimension_error',\n",
       "   'worst_radius',\n",
       "   'worst_texture',\n",
       "   'worst_perimeter',\n",
       "   'worst_area',\n",
       "   'worst_smoothness',\n",
       "   'worst_compactness',\n",
       "   'worst_concavity',\n",
       "   'worst_concave_points',\n",
       "   'worst_symmetry',\n",
       "   'worst_fractal_dimension'],\n",
       "  'Set': 'vali',\n",
       "  'Number_of_Data': {1: 70, 0: 44},\n",
       "  'f1_1': 1.0,\n",
       "  'f1_0': 1.0,\n",
       "  'f1_macro': 1.0,\n",
       "  'f1_micro': 1.0,\n",
       "  'prc_auc_1': 0.9999999999999999,\n",
       "  'prc_auc_0': 0.22409168083062822,\n",
       "  'precision_1': 1.0,\n",
       "  'precision_0': 1.0,\n",
       "  'macro_precision': 1.0,\n",
       "  'micro_precision': 1.0,\n",
       "  'recall_1': 1.0,\n",
       "  'recall_0': 1.0,\n",
       "  'macro_recall': 1.0,\n",
       "  'micro_recall': 1.0,\n",
       "  'accuracy': 1.0,\n",
       "  'roc_auc': 1.0,\n",
       "  'cross_entropy': 0.013380150817586648,\n",
       "  'fpr': [0.0, 0.0, 0.0, 1.0],\n",
       "  'tpr': [0.0, 0.014285714285714285, 1.0, 1.0],\n",
       "  'True_value': [1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  'Predict_value': [1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  'Predict_prob_value': [0.9453506464574714,\n",
       "   0.0004553214057071509,\n",
       "   0.1193875789120416,\n",
       "   0.9899053024140584,\n",
       "   0.9972450269971873,\n",
       "   0.9998208503797462,\n",
       "   0.043528557506378414,\n",
       "   0.0002297897030311269,\n",
       "   0.0004893812311508544,\n",
       "   0.011837723277556323,\n",
       "   0.9998847351607196,\n",
       "   0.9781971196188712,\n",
       "   0.9982037218392255,\n",
       "   0.9984850806623012,\n",
       "   0.9998915152963911,\n",
       "   0.9999158772336327,\n",
       "   0.00024397848002844492,\n",
       "   0.00010997334832719567,\n",
       "   0.9983357935991157,\n",
       "   0.00024183623387602404,\n",
       "   0.15423397355730714,\n",
       "   0.9998033103671669,\n",
       "   0.014315633529964898,\n",
       "   0.981952736508475,\n",
       "   0.00013538380994051815,\n",
       "   0.9999026080500779,\n",
       "   0.9990316988171047,\n",
       "   0.017176672843536262,\n",
       "   0.999511557948699,\n",
       "   0.9990698411437264,\n",
       "   0.9996585452295078,\n",
       "   0.9999341942619909,\n",
       "   0.9997977571318775,\n",
       "   0.00014232630744147936,\n",
       "   0.01113737918771715,\n",
       "   0.9999397569996715,\n",
       "   0.9966669126490844,\n",
       "   0.00019938649091401134,\n",
       "   0.9994561018705972,\n",
       "   0.008703439897516445,\n",
       "   0.00013749006629608978,\n",
       "   0.005246802016457175,\n",
       "   7.266173052889907e-05,\n",
       "   0.9487185051506377,\n",
       "   0.000411785657031715,\n",
       "   0.937968043274067,\n",
       "   0.9985263173383443,\n",
       "   0.9999257199592682,\n",
       "   0.9630584353397196,\n",
       "   0.9884560792072181,\n",
       "   0.00015826935595862258,\n",
       "   0.0001263898345032581,\n",
       "   0.010539370382971818,\n",
       "   0.9999355939681985,\n",
       "   0.9842323798915625,\n",
       "   0.9998510812570021,\n",
       "   0.9917466602224656,\n",
       "   0.9999302722697707,\n",
       "   0.046604598660069566,\n",
       "   0.999852725068949,\n",
       "   0.0015977434141760541,\n",
       "   0.9834860878257987,\n",
       "   0.011865375510105585,\n",
       "   0.9997932620449972,\n",
       "   0.0004219093277643047,\n",
       "   0.001912078640477238,\n",
       "   0.9998794240535861,\n",
       "   0.002030200376593682,\n",
       "   0.994154836693855,\n",
       "   0.9994092697475084,\n",
       "   0.0001451546815675963,\n",
       "   0.9963530373210089,\n",
       "   0.9999475660895756,\n",
       "   0.9563901111691039,\n",
       "   0.9998760587318991,\n",
       "   0.9782881551432404,\n",
       "   0.0004709064664042419,\n",
       "   0.9998830451466649,\n",
       "   0.00017312807911928164,\n",
       "   0.06727440911104685,\n",
       "   0.9988689671448322,\n",
       "   0.9859928811481328,\n",
       "   0.9999095551340598,\n",
       "   0.0016233221908155836,\n",
       "   0.9930219235777954,\n",
       "   0.9972701471816904,\n",
       "   0.9979202818281864,\n",
       "   0.9994149893277926,\n",
       "   0.997126751399156,\n",
       "   0.9378545758106649,\n",
       "   0.05894631983957724,\n",
       "   0.9941000718333507,\n",
       "   0.9892417644870722,\n",
       "   0.00012224172913657998,\n",
       "   0.006049319427043736,\n",
       "   0.9155287592345547,\n",
       "   4.501828754636588e-05,\n",
       "   0.9993032463376565,\n",
       "   0.012257734798100117,\n",
       "   0.020366008489980547,\n",
       "   0.07013666889312903,\n",
       "   0.9949316058147175,\n",
       "   0.9997612188234446,\n",
       "   0.9998046439839968,\n",
       "   0.9998995650027301,\n",
       "   0.9941721658440663,\n",
       "   0.11729900800576676,\n",
       "   0.9717986946879208,\n",
       "   0.9886113546216929,\n",
       "   0.9995393377133205,\n",
       "   0.005038646904553632,\n",
       "   0.9977584568791555,\n",
       "   0.9995546007983483,\n",
       "   0.9997489708649646],\n",
       "  'Best_Threshold': [0.6156776133205051,\n",
       "   0.24135092784756415,\n",
       "   0.2336292791682194,\n",
       "   0.32971747141136115,\n",
       "   0.1529843842837671,\n",
       "   0.3843307448687497,\n",
       "   0.24135092784756415,\n",
       "   0.24135092784756415,\n",
       "   0.49532261142066425,\n",
       "   0.567718469985449,\n",
       "   0.24135092784756415,\n",
       "   0.4906503165149528,\n",
       "   0.4909526285053476,\n",
       "   0.24135092784756415,\n",
       "   0.6013408427366176,\n",
       "   0.6156791506186637,\n",
       "   0.48432616284362373,\n",
       "   0.47158240417217606,\n",
       "   0.32971747141136115,\n",
       "   0.4966565364387161,\n",
       "   0.46100468666744854,\n",
       "   0.24135092784756415,\n",
       "   0.3843316205800557,\n",
       "   0.5844129887106144,\n",
       "   0.5516462836175299,\n",
       "   0.6156776133205051,\n",
       "   0.6156770281473449,\n",
       "   0.5651568140419021,\n",
       "   0.38433235668889715,\n",
       "   0.4730261373911418]},\n",
       " {'Model': 'LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy_LightGBM_XGBoost_Random Forest with Entropy',\n",
       "  'Features': ['mean_radius',\n",
       "   'mean_texture',\n",
       "   'mean_perimeter',\n",
       "   'mean_area',\n",
       "   'mean_smoothness',\n",
       "   'mean_compactness',\n",
       "   'mean_concavity',\n",
       "   'mean_concave_points',\n",
       "   'mean_symmetry',\n",
       "   'mean_fractal_dimension',\n",
       "   'radius_error',\n",
       "   'texture_error',\n",
       "   'perimeter_error',\n",
       "   'area_error',\n",
       "   'smoothness_error',\n",
       "   'compactness_error',\n",
       "   'concavity_error',\n",
       "   'concave_points_error',\n",
       "   'symmetry_error',\n",
       "   'fractal_dimension_error',\n",
       "   'worst_radius',\n",
       "   'worst_texture',\n",
       "   'worst_perimeter',\n",
       "   'worst_area',\n",
       "   'worst_smoothness',\n",
       "   'worst_compactness',\n",
       "   'worst_concavity',\n",
       "   'worst_concave_points',\n",
       "   'worst_symmetry',\n",
       "   'worst_fractal_dimension'],\n",
       "  'Set': 'test',\n",
       "  'Number_of_Data': {1: 79, 0: 35},\n",
       "  'f1_1': 0.9570552147239264,\n",
       "  'f1_0': 0.8923076923076922,\n",
       "  'f1_macro': 0.9246814535158093,\n",
       "  'f1_micro': 0.9385964912280702,\n",
       "  'prc_auc_1': 0.9927576450936533,\n",
       "  'prc_auc_0': 0.17243272558302342,\n",
       "  'precision_1': 0.9285714285714286,\n",
       "  'precision_0': 0.9666666666666667,\n",
       "  'macro_precision': 0.9476190476190476,\n",
       "  'micro_precision': 0.9385964912280702,\n",
       "  'recall_1': 0.9873417721518988,\n",
       "  'recall_0': 0.8285714285714286,\n",
       "  'macro_recall': 0.9079566003616637,\n",
       "  'micro_recall': 0.9385964912280702,\n",
       "  'accuracy': 0.9385964912280702,\n",
       "  'roc_auc': 0.9851717902350814,\n",
       "  'cross_entropy': 0.1299549303967804,\n",
       "  'fpr': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.02857142857142857,\n",
       "   0.02857142857142857,\n",
       "   0.05714285714285714,\n",
       "   0.05714285714285714,\n",
       "   0.08571428571428572,\n",
       "   0.08571428571428572,\n",
       "   0.17142857142857143,\n",
       "   0.17142857142857143,\n",
       "   1.0],\n",
       "  'tpr': [0.0,\n",
       "   0.012658227848101266,\n",
       "   0.6835443037974683,\n",
       "   0.6835443037974683,\n",
       "   0.9113924050632911,\n",
       "   0.9113924050632911,\n",
       "   0.9240506329113924,\n",
       "   0.9240506329113924,\n",
       "   0.9873417721518988,\n",
       "   0.9873417721518988,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'True_value': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  'Predict_value': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  'Predict_prob_value': [0.9935261794349733,\n",
       "   0.9969119166470392,\n",
       "   0.9970764392421809,\n",
       "   0.996531417401794,\n",
       "   0.00013566821316321966,\n",
       "   0.9895757089569861,\n",
       "   0.999784549915557,\n",
       "   0.0008652475754407298,\n",
       "   0.8705835279900974,\n",
       "   0.9828265687610631,\n",
       "   0.9978982037506147,\n",
       "   0.5695675361076621,\n",
       "   0.9985755118128001,\n",
       "   0.9919325713788155,\n",
       "   0.9962082073089992,\n",
       "   0.9967044029454192,\n",
       "   0.9944262650029717,\n",
       "   0.7987337182266896,\n",
       "   0.9945713740825542,\n",
       "   0.31121279308394434,\n",
       "   0.007277824610930851,\n",
       "   0.9982916701158442,\n",
       "   0.9956727190356219,\n",
       "   0.9819111079560121,\n",
       "   0.7174323468950778,\n",
       "   0.005198720131820495,\n",
       "   0.9864239454955722,\n",
       "   0.9449721965777645,\n",
       "   0.5595925966133312,\n",
       "   0.9844844061517565,\n",
       "   0.29367262082803963,\n",
       "   9.664871660687357e-05,\n",
       "   0.002212428787533484,\n",
       "   0.9995886610611566,\n",
       "   0.00025403757199061344,\n",
       "   0.9960773509133081,\n",
       "   0.9999158263291277,\n",
       "   0.9957868797829046,\n",
       "   0.9987860628236139,\n",
       "   0.00047411655067745986,\n",
       "   0.0005661986278172801,\n",
       "   0.9235806995005726,\n",
       "   0.9912252251851814,\n",
       "   0.8096676683169327,\n",
       "   0.9995347136255845,\n",
       "   0.9956498089700135,\n",
       "   0.9999023251002647,\n",
       "   0.834735954784589,\n",
       "   0.6296123519284131,\n",
       "   0.9984836819687521,\n",
       "   0.9858866399067667,\n",
       "   0.9985274984881245,\n",
       "   0.9967849497426983,\n",
       "   0.989647735290381,\n",
       "   0.9999623172147808,\n",
       "   0.9826551099416857,\n",
       "   0.999930171751782,\n",
       "   0.0002164420794067169,\n",
       "   0.9573603342038339,\n",
       "   0.9998921125583897,\n",
       "   0.9992805136921048,\n",
       "   0.00021998125750758444,\n",
       "   0.9999443566307168,\n",
       "   0.03262204504640408,\n",
       "   0.7752071000876307,\n",
       "   7.658733074491253e-05,\n",
       "   0.9999254886589805,\n",
       "   0.005038816722204683,\n",
       "   0.008516477707403585,\n",
       "   0.991522146603193,\n",
       "   0.05618269824725004,\n",
       "   0.9873849100648336,\n",
       "   0.9999252991195432,\n",
       "   0.9999616193421499,\n",
       "   0.6925111854651713,\n",
       "   0.9964828559980242,\n",
       "   0.9991921255924889,\n",
       "   0.9947804460029415,\n",
       "   0.9969481849883548,\n",
       "   0.9992794698842337,\n",
       "   9.581326932211112e-05,\n",
       "   0.021146062864051917,\n",
       "   0.9936531137594281,\n",
       "   0.00022752097402560563,\n",
       "   0.005384346463204516,\n",
       "   0.786198492088866,\n",
       "   0.9998373438668355,\n",
       "   0.9981999986466313,\n",
       "   0.01133869748912588,\n",
       "   0.9963524966770698,\n",
       "   0.9599217992714519,\n",
       "   0.012747450094715134,\n",
       "   0.99988251129582,\n",
       "   0.00017444503316423602,\n",
       "   0.9995308916595497,\n",
       "   0.9995809031339494,\n",
       "   0.9985874824842828,\n",
       "   0.9998582775728392,\n",
       "   0.9962188981480756,\n",
       "   0.7766622717123486,\n",
       "   0.04326878905134039,\n",
       "   0.998249366359605,\n",
       "   0.43181016198004474,\n",
       "   0.9992753959656163,\n",
       "   0.03357035182606197,\n",
       "   0.0005423786999758878,\n",
       "   0.9194151833757525,\n",
       "   0.9890222595265059,\n",
       "   0.002099845108758709,\n",
       "   0.02966660152062737,\n",
       "   0.9619946284512454,\n",
       "   0.9977890217849662,\n",
       "   0.9126873301946253,\n",
       "   0.8917273400866946],\n",
       "  'Best_Threshold': [0.6156776133205051,\n",
       "   0.24135092784756415,\n",
       "   0.2336292791682194,\n",
       "   0.32971747141136115,\n",
       "   0.1529843842837671,\n",
       "   0.3843307448687497,\n",
       "   0.24135092784756415,\n",
       "   0.24135092784756415,\n",
       "   0.49532261142066425,\n",
       "   0.567718469985449,\n",
       "   0.24135092784756415,\n",
       "   0.4906503165149528,\n",
       "   0.4909526285053476,\n",
       "   0.24135092784756415,\n",
       "   0.6013408427366176,\n",
       "   0.6156791506186637,\n",
       "   0.48432616284362373,\n",
       "   0.47158240417217606,\n",
       "   0.32971747141136115,\n",
       "   0.4966565364387161,\n",
       "   0.46100468666744854,\n",
       "   0.24135092784756415,\n",
       "   0.3843316205800557,\n",
       "   0.5844129887106144,\n",
       "   0.5516462836175299,\n",
       "   0.6156776133205051,\n",
       "   0.6156770281473449,\n",
       "   0.5651568140419021,\n",
       "   0.38433235668889715,\n",
       "   0.4730261373911418]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allResult[0][\"Evaluation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Set</th>\n",
       "      <th>Number_of_Data</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>prc_auc_1</th>\n",
       "      <th>prc_auc_0</th>\n",
       "      <th>...</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>True_value</th>\n",
       "      <th>Predict_value</th>\n",
       "      <th>Predict_prob_value</th>\n",
       "      <th>Best_Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_XGBoost_Random Forest with Entropy_Li...</td>\n",
       "      <td>[mean_radius, mean_texture, mean_perimeter, me...</td>\n",
       "      <td>train</td>\n",
       "      <td>{1: 208, 0: 133}</td>\n",
       "      <td>0.992840</td>\n",
       "      <td>0.988593</td>\n",
       "      <td>0.990717</td>\n",
       "      <td>0.991202</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.226889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991202</td>\n",
       "      <td>0.991202</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.027259</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.007518796992481203, 0.007518...</td>\n",
       "      <td>[0.0, 0.004807692307692308, 0.9855769230769231...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0.99950809699604, 0.0002532106571830315, 0.97...</td>\n",
       "      <td>[0.6156776133205051, 0.24135092784756415, 0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_XGBoost_Random Forest with Entropy_Li...</td>\n",
       "      <td>[mean_radius, mean_texture, mean_perimeter, me...</td>\n",
       "      <td>vali</td>\n",
       "      <td>{1: 70, 0: 44}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224092</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013380</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.014285714285714285, 1.0, 1.0]</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.9453506464574714, 0.0004553214057071509, 0....</td>\n",
       "      <td>[0.6156776133205051, 0.24135092784756415, 0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_XGBoost_Random Forest with Entropy_Li...</td>\n",
       "      <td>[mean_radius, mean_texture, mean_perimeter, me...</td>\n",
       "      <td>test</td>\n",
       "      <td>{1: 79, 0: 35}</td>\n",
       "      <td>0.957055</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.924681</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.992758</td>\n",
       "      <td>0.172433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.985172</td>\n",
       "      <td>0.129955</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.02857142857142857, 0.0285714...</td>\n",
       "      <td>[0.0, 0.012658227848101266, 0.6835443037974683...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.9935261794349733, 0.9969119166470392, 0.997...</td>\n",
       "      <td>[0.6156776133205051, 0.24135092784756415, 0.23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "0  LightGBM_XGBoost_Random Forest with Entropy_Li...   \n",
       "1  LightGBM_XGBoost_Random Forest with Entropy_Li...   \n",
       "2  LightGBM_XGBoost_Random Forest with Entropy_Li...   \n",
       "\n",
       "                                            Features    Set    Number_of_Data  \\\n",
       "0  [mean_radius, mean_texture, mean_perimeter, me...  train  {1: 208, 0: 133}   \n",
       "1  [mean_radius, mean_texture, mean_perimeter, me...   vali    {1: 70, 0: 44}   \n",
       "2  [mean_radius, mean_texture, mean_perimeter, me...   test    {1: 79, 0: 35}   \n",
       "\n",
       "       f1_1      f1_0  f1_macro  f1_micro  prc_auc_1  prc_auc_0  ...  \\\n",
       "0  0.992840  0.988593  0.990717  0.991202   0.999862   0.226889  ...   \n",
       "1  1.000000  1.000000  1.000000  1.000000   1.000000   0.224092  ...   \n",
       "2  0.957055  0.892308  0.924681  0.938596   0.992758   0.172433  ...   \n",
       "\n",
       "   micro_recall  accuracy   roc_auc  cross_entropy  \\\n",
       "0      0.991202  0.991202  0.999783       0.027259   \n",
       "1      1.000000  1.000000  1.000000       0.013380   \n",
       "2      0.938596  0.938596  0.985172       0.129955   \n",
       "\n",
       "                                                 fpr  \\\n",
       "0  [0.0, 0.0, 0.0, 0.007518796992481203, 0.007518...   \n",
       "1                               [0.0, 0.0, 0.0, 1.0]   \n",
       "2  [0.0, 0.0, 0.0, 0.02857142857142857, 0.0285714...   \n",
       "\n",
       "                                                 tpr  \\\n",
       "0  [0.0, 0.004807692307692308, 0.9855769230769231...   \n",
       "1              [0.0, 0.014285714285714285, 1.0, 1.0]   \n",
       "2  [0.0, 0.012658227848101266, 0.6835443037974683...   \n",
       "\n",
       "                                          True_value  \\\n",
       "0  [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, ...   \n",
       "1  [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, ...   \n",
       "\n",
       "                                       Predict_value  \\\n",
       "0  [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, ...   \n",
       "1  [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                  Predict_prob_value  \\\n",
       "0  [0.99950809699604, 0.0002532106571830315, 0.97...   \n",
       "1  [0.9453506464574714, 0.0004553214057071509, 0....   \n",
       "2  [0.9935261794349733, 0.9969119166470392, 0.997...   \n",
       "\n",
       "                                      Best_Threshold  \n",
       "0  [0.6156776133205051, 0.24135092784756415, 0.23...  \n",
       "1  [0.6156776133205051, 0.24135092784756415, 0.23...  \n",
       "2  [0.6156776133205051, 0.24135092784756415, 0.23...  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(result[\"Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"PermutationImportance\"][\"originalData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"PermutationImportance\"][\"trainData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作範例 - Iris Datasets（Multi-class Classification）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = load_iris(as_frame = True)[\"data\"]\n",
    "rawData = pd.concat([rawData, load_iris(as_frame = True)[\"target\"]], axis = 1)\n",
    "rawData = rawData.rename(\n",
    "    columns = {\n",
    "        \"sepal length (cm)\": \"sepal_length_(cm)\",\n",
    "        \"sepal width (cm)\": \"sepal_width_(cm)\",\n",
    "        \"petal length (cm)\": \"petal_length_(cm)\",\n",
    "        \"petal width (cm)\": \"'petal_width_(cm)\"\n",
    "    }\n",
    ")\n",
    "trainData, testData = train_test_split(rawData, test_size = 0.2, shuffle = True) \n",
    "trainData, valiData = train_test_split(trainData, test_size = 0.25, shuffle = True) \n",
    "trainData, valiData, testData = trainData.reset_index(drop = True), valiData.reset_index(drop = True), testData.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineer and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoML_Flow.Model_Training_and_Evaluation_Flow import modelTrainingFlow \n",
    "for oneFE in featureEngineerFlow:\n",
    "    totalResult = modelTrainingFlow(\n",
    "        trainData = trainData,\n",
    "        valiData = valiData,\n",
    "        testData = testData,\n",
    "        inputFeatures = trainData.drop(columns = [\"target\"]).columns.tolist(), \n",
    "        target = \"target\", \n",
    "        targetType = \"classification\",\n",
    "        ml_methods = oneFE,\n",
    "        HTMetric = \"cross_entropy\",\n",
    "        thresholdMetric = \"f1_1\", \n",
    "        featureSelection = oneFE[\"FeatureSelection\"],\n",
    "        hyperparameter_tuning_method = \"TPESampler\", \n",
    "        hyperparameter_tuning_epochs = 1\n",
    "    )\n",
    "    result = totalResult.fit(permutationImportanceMethod = [\"trainData\", \"originalData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"PermutationImportance\"][\"originalData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[\"PermutationImportance\"][\"trainData\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作範例 - Diabete Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = load_diabetes(as_frame = True)[\"data\"]\n",
    "rawData = pd.concat([rawData, load_diabetes(as_frame = True)[\"target\"]], axis = 1)\n",
    "trainData, testData = train_test_split(rawData, test_size = 0.2, shuffle = True) \n",
    "trainData, valiData = train_test_split(trainData, test_size = 0.25, shuffle = True) \n",
    "trainData, valiData, testData = trainData.reset_index(drop = True), valiData.reset_index(drop = True), testData.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineer and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from AutoML_Flow.Model_Training_and_Evaluation_Flow import modelTrainingFlow \n",
    "for oneFE in featureEngineerFlow:\n",
    "    modelTrainingFlow = modelTrainingFlow(\n",
    "        trainData = trainData,\n",
    "        valiData = valiData,\n",
    "        testData = testData,\n",
    "        inputFeatures = trainData.drop(columns = [\"target\"]).columns.tolist(), \n",
    "        target = \"target\", \n",
    "        ml_methods = oneFE,\n",
    "        targetType = \"regression\",\n",
    "        HTMetric = \"RMSE\", \n",
    "        hyperparameter_tuning_method = \"TPESampler\", \n",
    "        hyperparameter_tuning_epochs = 1, \n",
    "        featureSelection = oneFE[\"FeatureSelection\"],\n",
    "        importanceMethod = [\"None\"],\n",
    "        modelNameList = [\n",
    "            [\"LightGBM\", \"CatBoost\"]\n",
    "        ]\n",
    "    )\n",
    "    totalResult = modelTrainingFlow.fit()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(totalResult[\"Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(totalResult[\"Evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不平衡資料處理範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.datasets import fetch_dataset\n",
    "dataset = fetch_dataset()[\"thyroid_sick\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "af4a1e6a86c740b63a37040b3f0131c5c5c454fa1507d305e6c23d6bab4bfa1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
